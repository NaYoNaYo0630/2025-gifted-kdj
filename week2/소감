오늘 배운 내용은 저번 시간에 배웠던 간략하게 배웠던 LLM을 이제 딥러닝 시스템과 접목하여 좀더 나은 방식으로 개선하였다.  
언어 처리 모델에서는 가변하는 입력을 다루기 위해 순환 신경망을 이용해 이 문제점을 해결하였다.  
순환신경망은 간략히 이전 문장 까지의 정보를 함축화하여 한 개의 입력을 받는 방식이었다. 
이제 본격적으로 NLP의 역사, 목표 그리고 활용 사례 등을 배우면서 가장 중요한 작동원리를 알게 되었다. 
또한 hugging face에서 여러 모델을 불러오는 방법을 배우고 이중에서 GPT-2 등 
구식의 NLP로 다양한 프롬프트로 원하는 답안을 출력 시키기 위한 노력을 했다.  
마지막으로 이런 답안을 효과적으로 출력하는 프롬프트 방식과 이런 프롬프트 방식이 필요 없어도 
잘 작동되는 모델의 작동 방식까지 배우며 2주차를 마쳤다. 
우리 주변에서 흔히 볼 수 있는 챗 GPT 같은 NLP를 직접 다뤄보고 여러가지를 조정해 보면서 한 층 더 가까워진 기분이 들었다.
난 GPT를 자주 사용하는 만큼 오늘 배운 것을 잘 써먹어 좀 더 개선된 답안을 얻을 것이다. 
