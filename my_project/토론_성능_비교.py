"""
timHan/llama3.2korean3B4QKM:latest
openchat:latest
mistral:latest
exaone3.5:latest
gemma3:latest
llama3.2:latest
    """

import uuid
import streamlit as st
import ollama
from utils import check_ollama
import re

def clean_surrogates(text):
    return re.sub(r'[\ud800-\udfff]', '', text)

st.set_page_config(page_title="AI Debate Room")
st.sidebar.title("Settings")

if "languages" not in st.session_state:
    st.session_state.languages = ""
languages = ['Korean', 'English']
st.session_state.languages = st.sidebar.selectbox("Choose languages", languages)

NumberOfAi = [2, 3, 4, 5]
if "NumberOfAi" not in st.session_state:
    st.session_state.NumberOfAi = 2

selected_num = st.sidebar.selectbox(
    "Choose the number of AI",
    NumberOfAi,
    index=NumberOfAi.index(st.session_state["NumberOfAi"])
)
if selected_num != st.session_state["NumberOfAi"]:
    st.session_state["NumberOfAi"] = selected_num

for i in range(max(NumberOfAi)):
    key = f"AI{i+1}_setting"
    if i < st.session_state["NumberOfAi"]:
        st.session_state[key] = st.sidebar.text_area(
            f"AI{i+1} ì£¼ìž¥ ê²½í–¥ì„± ì„¤ì •",
            value=st.session_state.get(key, ""),
            help=f"AI{i+1}ì˜ ì£¼ìž¥ ê°€ëŠ¥ì„± ë©”ì‹œì§€ ì„¤ì •"
        )

if "model" not in st.session_state:
    check_ollama()
    model_list = [m["model"] for m in ollama.list()["models"]]
    st.session_state.model = model_list[0] if model_list else ""

models = [m["model"] for m in ollama.list()["models"]]
for i in range(st.session_state["NumberOfAi"]):
    key = f"AI{i+1}_model"
    default_index = 0
    if key in st.session_state and st.session_state[key] in models:
        default_index = models.index(st.session_state[key])

    st.sidebar.selectbox(
        f"AI{i+1} ëª¨ë¸ ì„¤ì •",
        models,
        index=default_index,
        key=key
    )

# ê³µí†µ í•˜ì´í¼íŒŒë¼ë¯¸í„°
st.sidebar.markdown("### âš™ï¸ ê³µí†µ ì„¤ì •")
temperature = st.sidebar.slider("temperature", 0.0, 1.5, 0.2, 0.1)
top_p = st.sidebar.slider("top_p", 0.1, 1.0, 0.9, 0.05)
max_sents = st.sidebar.slider("ë°œì–¸ ë¬¸ìž¥ ìˆ˜(ê¶Œìž¥ ìµœëŒ€)", 3, 8, 6, 1)

system_prompt = st.sidebar.text_area("System Prompt")

if "chats" not in st.session_state:
    st.session_state.chats = {}
if "current_chat_id" not in st.session_state:
    st.session_state.current_chat_id = None

if st.sidebar.button("\u2795 New Chat"):
    chat_id = str(uuid.uuid4())
    st.session_state.current_chat_id = chat_id
    st.session_state.chats[chat_id] = {
        "name": "ìƒˆë¡œìš´ ì±„íŒ…",
        "messages": [{"role": "system", "content": system_prompt}]
    }
for cid, chat_info in st.session_state.chats.items():
    if st.sidebar.button(chat_info["name"], key=cid):
        st.session_state.current_chat_id = cid

emoji_numbers = ["1ï¸âƒ£", "2ï¸âƒ£", "3ï¸âƒ£", "4ï¸âƒ£", "5ï¸âƒ£"]
st.session_state.avatar_map = {f"AI{i+1}": emoji_numbers[i] for i in range(st.session_state["NumberOfAi"])}
st.session_state.avatar_map["user"] = "ðŸ‘¤"

avatar_map = st.session_state.avatar_map
num_ai = st.session_state.NumberOfAi

st.session_state.setdefault("show_user_judge", False)
st.session_state.setdefault("show_model_judge", False)
st.session_state.setdefault("user_judge_choice", "")
st.session_state.setdefault("judge_result", "")

chat_id = st.session_state.current_chat_id
if chat_id:
    chat = st.session_state.chats[chat_id]
    st.title(chat["name"])

    for msg in chat["messages"]:
        if msg["role"] == "system":
            continue
        if msg["role"] == "user" and (
            "just said:" in msg["content"] 
            or "Please rebut" in msg["content"]
            or "âš ï¸ ë‹¹ì‹ ì˜ ë°œì–¸ì´ ë„ˆë¬´ ì¤‘ë¦½ì ìž…ë‹ˆë‹¤. ìžì‹ ì˜ ìž…ìž¥ì„ ê°•í•˜ê²Œ ë‹¤ì‹œ ì£¼ìž¥í•˜ì„¸ìš”. ì¤‘ë¦½ì  ë¹„êµëŠ” í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤." in msg["content"]
            or "âš ï¸ Your response was too neutral. Reassert your stance strongly. Neutral comparisons are not allowed." in msg["content"]
        ):
            continue
        if msg["role"].endswith("_instruction"):
            continue

        avatar = avatar_map.get(msg["role"], "ðŸ’¬")
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(msg["content"])

    user_input = st.chat_input("Enter debate topic or reply")

    if user_input:
        chat["messages"].append({"role": "user", "content": user_input})
        with st.chat_message("user", avatar=avatar_map["user"]):
            st.markdown(user_input)

        if len(chat["messages"]) == 3 and chat["name"] == "ìƒˆë¡œìš´ ì±„íŒ…":
            summary_prompt = [
                {"role": "system", "content": "You are a helpful assistant that creates concise chat titles."},
                {"role": "user", "content": f"Generate a short (max 5 words) title summarizing the conversation:\nUser: {chat['messages'][1]['content']}"}
            ]
            try:
                stream = ollama.chat(model=st.session_state.model, messages=summary_prompt, stream=True)
                new_title = ""
                for chunk in stream:
                    new_title += chunk.message.content
                chat["name"] = new_title.strip()
                st.rerun()
            except:
                pass


        max_turns = 3
        for turn in range(max_turns):
            st.divider()
            for i in range(num_ai):
                ai_role = f"AI{i+1}"
                setting_key = f"AI{i+1}_setting"
                setting = st.session_state.get(setting_key, "")
                opponents = [f"AI{j+1}" for j in range(num_ai) if j != i]
                opponent_str = ", ".join(opponents)
                response = ""
                previous_response = response
                system_intro = (
                    f"You are {ai_role} and are debating with {opponent_str}. "
                    f"Your fixed position is {setting} and you should never deviate from this argument. "
                    f"Rebut your opponent's argument, {previous_response}. Write in 3 sentences at most."
                ) if st.session_state.languages == "English" else (
                    f"ë‹¹ì‹ ì€ {ai_role}ì´ë©°, {opponent_str}ì™€ í† ë¡  ì¤‘ìž…ë‹ˆë‹¤. "
                    f"ë‹¹ì‹ ì˜ ê³ ì • ìž…ìž¥ì€ {setting}ì´ë©° ì´ ì£¼ìž¥ì—ì„œ ì ˆëŒ€ë¡œ ë²—ì–´ë‚˜ì§€ ë§ˆì„¸ìš”. "
                    f"ìƒëŒ€ì˜ ì£¼ìž¥ì¸ {previous_response}ë¥¼ ë°˜ë°•í•˜ì„¸ìš”. ìµœëŒ€ 3ë¬¸ìž¥ìœ¼ë¡œ ìž‘ì„±í•˜ì„¸ìš”."
                )

                messages = [{"role": "system", "content": system_intro}] + chat["messages"]
                response = ollama.chat(
                    model=st.session_state.model,
                    messages=messages,
                    stream=False,
                    options={
                        "top_p": 1.4,
                        "temperature": 1.0
                    }
                )["message"]["content"]
                
                with st.chat_message(ai_role, avatar=avatar_map[ai_role]):
                    st.markdown(response)

                chat["messages"].append({"role": ai_role, "content": response})
                neutral_keywords = [
                    "both", "depends", "personal preference", "ì¤‘ë¦½", "ì„ í˜¸", "ì·¨í–¥", "ê· í˜•", "ìž¥ë‹¨ì ", "equally valid"
                ]
                if any(keyword.lower() in response.lower() for keyword in neutral_keywords):
                    feedback = (
                        "âš ï¸ Your response was too neutral. Reassert your stance strongly. Neutral comparisons are not allowed."
                        if st.session_state.languages == "English"
                        else "âš ï¸ ë‹¹ì‹ ì˜ ë°œì–¸ì´ ë„ˆë¬´ ì¤‘ë¦½ì ìž…ë‹ˆë‹¤. ìžì‹ ì˜ ìž…ìž¥ì„ ê°•í•˜ê²Œ ë‹¤ì‹œ ì£¼ìž¥í•˜ì„¸ìš”. ì¤‘ë¦½ì  ë¹„êµëŠ” í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                    )
                    chat["messages"].append({
                        "role": "user",
                        "content": feedback
                    })
                chat["messages"].append({
                    "role": "user",
                    "content": f"{opponent_str} just said: {response}\nPlease rebut and make your own argument. No more than 3 sentences."
                })

            # 1. ì‚¬ìš©ìž íŒë‹¨ ë²„íŠ¼
    if st.button("ðŸ‘¤ ì‚¬ìš©ìž ìŠ¹ìž ì„ íƒ", key="user_judge_btn"):
        st.session_state.show_user_judge = True
        st.rerun()

    # 2. íŒë‹¨ ì„ íƒ ì°½
    if st.session_state.get("show_user_judge", False):
        choice = st.selectbox(
            "ìŠ¹ìžë¥¼ ì„ íƒí•˜ì„¸ìš”",
            [f"AI{i+1}" for i in range(num_ai)],
            key="user_choice_select"
        )
        st.session_state.user_judge_choice = choice
        st.success(f"ðŸ‘¤ ì‚¬ìš©ìž íŒë‹¨: {choice} ìŠ¹ë¦¬!")

            # 3. ì„ íƒëœ AI ì´ì–´ê°€ê¸°
        if st.button("ì„ íƒëœ AIê°€ ì£¼ìž¥ ì´ì–´ê°€ê¸°", key="continue_arg"):
            ai_idx = int(choice.replace("AI", "")) - 1
            ai_role = f"AI{ai_idx+1}"
            setting = st.session_state.get(f"AI{ai_idx+1}_setting", "")
            opponent_str = ", ".join([f"AI{j+1}" for j in range(num_ai) if j != ai_idx])
            system_intro = (
                f"You are {ai_role}. Continue your argument logically against {opponent_str}. " +
                setting + " " +
                ("Do not mention the prompt. Expand your idea concisely." if st.session_state.languages == "English"
                else "í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ ë§í•˜ì§€ ë§ê³  ìžì‹ ì˜ ì£¼ìž¥ì„ ê°„ê²°í•˜ê³  ë…¼ë¦¬ì ìœ¼ë¡œ ì´ì–´ê°€ì„¸ìš”.")
            )
            messages = [{"role": "system", "content": system_intro}] + chat["messages"]
            response = ollama.chat(model=st.session_state.model, messages=messages, stream=False)["message"]["content"]
            with st.chat_message(ai_role, avatar=avatar_map[ai_role]):
                st.markdown(response)
                chat["messages"].append({"role": ai_role, "content": response})
                st.session_state.show_user_judge = False

        if st.button("ðŸ§ JudgeModel ì¡°ì–¸"):
            st.session_state.show_model_judge = True
        if st.session_state.show_model_judge:
            judge_instruction = {
                "Korean": (
                    "ë§Žì€ ì°¸ê°€ìž ì¤‘ì— ì œì¼ ë…¼ë¦¬ì ì´ê³  ì„¤ë“ë ¥ ìžˆëŠ” ì‚¬ëžŒì„ ë”± 1ëª…ë§Œ ë½‘ì•„ì¤˜. ê·¸ ì‚¬ëžŒì˜ ì´ë¦„ë§Œ ë§í•´. ì˜ˆë¥¼ ë“¤ì–´ 'AI1' ì´ë ‡ê²Œ."
                ),
                "English": (
                        "You are a fair debate judge. Read the conversation and decide which AI presented the more logical and persuasive argument.\n"
                        "Output in the following format:\n\n"
                        "[Winner] : AI1 or AI2\n[Reason] : Detailed explanation"
                )
            }
            judge_prompt = [
                {"role": "system", "content": judge_instruction[st.session_state.languages]},
                *chat["messages"]
            ]
            judge_model = "mistral"
            judge_result = ollama.chat(model=judge_model, messages=judge_prompt, stream=False)["message"]["content"]
            st.session_state.judge_result = judge_result

        if st.session_state.judge_result:
            st.markdown(f"### ðŸ§‘â€âš–ï¸ JudgeModel íŒë‹¨ ê²°ê³¼\n{st.session_state.judge_result}")

else:
    st.info("ì˜¤ëŠ˜ì˜ í† ë¡  ì£¼ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?\nì™¼ìª½ì—ì„œ ì±„íŒ…ì„ ì„ íƒí•˜ê±°ë‚˜ ìƒˆ ì±„íŒ…ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.")
