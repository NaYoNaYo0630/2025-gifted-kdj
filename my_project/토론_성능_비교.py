import os
import re
import json
import time
import random
from typing import Dict, List, Tuple, Optional

import pandas as pd
import streamlit as st
import ollama
from utils import check_ollama

# ================== ìƒìˆ˜ ==================
LETTERS = ["A", "B", "C", "D"]

# ================== ê³µìš© ìœ í‹¸ ==================
def clean_surrogates(text: str) -> str:
    return re.sub(r'[\ud800-\udfff]', '', text or "")

def safe_json_loads(payload: str) -> Optional[dict]:
    """
    ëª¨ë¸ì´ ì½”ë“œíœìŠ¤ë‚˜ ì•ë’¤ ì¡ìŒì„ ë§ë¶™ì˜€ì„ ë•Œë„ JSONë§Œ ì¶”ì¶œí•´ì„œ íŒŒì‹±.
    """
    if not payload:
        return None
    # ê°€ì¥ ë°”ê¹¥ { ... } ë¸”ë¡ë§Œ ì¶”ì¶œ
    m = re.search(r"\{.*\}", payload, re.S)
    if not m:
        return None
    try:
        return json.loads(m.group(0))
    except Exception:
        return None

@st.cache_data(show_spinner=False)
def load_questions():
    """
    ë„ë©”ì¸(ë¶„ì•¼) -> {qid: item} í˜•íƒœ/ê¸°ì¡´ í‰íƒ„ í˜•íƒœ ëª¨ë‘ ì§€ì›.
    ë°˜í™˜: (flat_questions, domain_index, qid2domain)
    """
    candidates = [
        "pages/mmlu_debate_questions.json",
        "mmlu_debate_questions.json",
        r"C:\Users\USER\ollama\pages\mmlu_debate_questions.json",
    ]
    for p in candidates:
        if os.path.exists(p):
            with open(p, "r", encoding="utf-8") as f:
                raw = json.load(f)

            def looks_like_question(d: dict) -> bool:
                return isinstance(d, dict) and {"question", "choices", "answer"}.issubset(d.keys())

            is_nested = all(isinstance(v, dict) for v in raw.values()) and not any(
                looks_like_question(v) for v in raw.values()
            )

            flat, domain_index, qid2domain = {}, {}, {}
            if is_nested:
                for domain, items in raw.items():
                    if not isinstance(items, dict):
                        continue
                    domain_index.setdefault(domain, [])
                    for qid, item in items.items():
                        if not looks_like_question(item):
                            continue
                        flat[qid] = item
                        flat[qid]["topic"] = item.get("topic") or domain
                        domain_index[domain].append(qid)
                        qid2domain[qid] = domain
            else:
                for qid, item in raw.items():
                    if not looks_like_question(item):
                        continue
                    flat[qid] = item
                    dom = item.get("topic", "Misc")
                    domain_index.setdefault(dom, []).append(qid)
                    qid2domain[qid] = dom
                    flat[qid]["topic"] = flat[qid].get("topic", dom)
            return flat, domain_index, qid2domain

    st.error("mmlu_debate_questions.json íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìœ„ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

def extract_choice_strict(text: str) -> str:
    """
    Judge ì „ìš©: íƒœê·¸ í•œ ì¤„ or 'ì •ë‹µ/answer/final: X' í•œ ì¤„ë§Œ ì¸ì •.
    """
    t = (text or "").strip()
    m = re.search(r"<answer>\s*([ABCD])\s*</answer>", t, re.I)
    if m:
        return m.group(1).upper()
    m = re.fullmatch(r"(?:ì •ë‹µ|answer|final)\s*(?:is|:|=)?\s*([ABCD])\s*", t, re.I)
    if m:
        return m.group(1).upper()
    return ""

def extract_choice(text: str) -> str:
    t = (text or "").strip()
    m = re.search(r"<answer>\s*([ABCD])\s*</answer>", t, re.I)
    if m: return m.group(1).upper()
    m = re.search(r"(ì •ë‹µ|answer|final)\s*(is|:|=)?\s*([ABCD])\b", t, re.I)
    if m: return m.group(3).upper()
    for line in t.splitlines():
        m = re.match(r"^\s*[\(\[\{<]?\s*([ABCD])\s*[\)\]\}>]?\s*$", line.strip(), re.I)
        if m: return m.group(1).upper()
    m = re.findall(r"(?<![A-Z])([ABCD])(?![A-Z])", t.upper())
    return m[0] if m else ""

def normalize_item_in_place(q: dict):
    # í‚¤ ì´ë¦„ ë³´ì •
    if "question" not in q and "prompt" in q:
        q["question"] = q["prompt"]
    if "choices" not in q and "answers" in q:
        q["choices"] = q["answers"]
    if "answer" not in q and "gold" in q:
        q["answer"] = q["gold"]

    # ì„ íƒì§€ í˜•íƒœ ë³´ì • â†’ ABCD dict
    if isinstance(q.get("choices"), list):
        q["choices"] = {LETTERS[i]: q["choices"][i] for i in range(min(4, len(q["choices"])))}
    elif isinstance(q.get("choices"), dict):
        ks = list(q["choices"].keys())
        if any(k not in LETTERS for k in ks):
            vals = list(q["choices"].values())
            q["choices"] = {LETTERS[i]: vals[i] for i in range(min(4, len(vals)))}

    # topic ê¸°ë³¸
    if not q.get("topic"):
        q["topic"] = "(ë¯¸ë¶„ë¥˜)"

def validate_item_or_stop(qid: str, q: dict):
    need = ["question", "choices", "answer"]
    miss = [k for k in need if k not in q]
    if miss:
        st.error(f"[{qid}] ë¬¸í•­ í‚¤ ëˆ„ë½: {miss}")
        st.json(q); st.stop()
    if not isinstance(q["choices"], dict):
        st.error(f"[{qid}] choicesê°€ dictê°€ ì•„ë‹™ë‹ˆë‹¤.")
        st.json(q); st.stop()
    # ì„ íƒì§€ëŠ” A/B/C/Dë§Œ ìœ ì§€
    for k in list(q["choices"].keys()):
        if k not in LETTERS:
            del q["choices"][k]
    if len(q["choices"]) < 2:
        st.error(f"[{qid}] ì„ íƒì§€ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        st.json(q); st.stop()
    # 4ì§€ì„ ë‹¤ ê°€ì •
    if any(k not in q["choices"] for k in LETTERS):
        st.error(f"[{qid}] í† ë¡  ëª¨ë“œìš© 4ì§€ì„ ë‹¤(ABCD) í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        st.json(q); st.stop()

# ================== Ollama ë˜í¼ ==================
def chat_once(model: str, messages: list, temperature: float, top_p: float, keep_alive: str = "5m", **options) -> str:
    """
    í•œ ë²ˆ í˜¸ì¶œ. keep_aliveë¡œ ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ìœ ì§€í•´ ë°˜ë³µ í˜¸ì¶œ ë¹„ìš©ì„ ì¤„ì„.
    """
    opts = {"temperature": float(temperature), "top_p": float(top_p), "keep_alive": keep_alive}
    opts.update(options or {})
    res = ollama.chat(model=model, messages=messages, stream=False, options=opts)
    return clean_surrogates(res.get("message", {}).get("content", ""))

# ================== í† ë¡  í”„ë¡¬í”„íŠ¸ ==================
def make_debater_system(ai_role: str, letter: str, claim: str, max_sents: int) -> str:
    return (
        f"ì—­í• : {ai_role}\n"
        f"ë‹´ë‹¹ ì„ íƒì§€: {letter}\n"
        f"ëª©í‘œ: ì˜¤ì§ ì„ íƒì§€ {letter}({claim})ê°€ ì˜³ë‹¤ê³  ê°•ë ¥íˆ ì˜¹í˜¸í•˜ë¼.\n\n"
        "ê·œì¹™:\n"
        f"- '{letter}' ì™¸ ë‹¤ë¥¸ ì„ íƒì§€ê°€ ë” ë‚«ë‹¤ê³  ë§í•˜ì§€ ë§ˆë¼.\n"
        "- 'ì •ë‹µì€ C' ê°™ì€ í‘œí˜„ ê¸ˆì§€.\n"
        "- ë°˜ëŒ€ ì„ íƒì§€ì˜ ì•½ì ì„ ìµœì†Œ 2ê°€ì§€ ì§€ì í•˜ë¼.\n"
        f"- í•œêµ­ì–´ë¡œë§Œ, {max_sents}ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ.\n"
    )

def make_debater_user(q: dict, letter: str) -> str:
    choices_str = "\n".join([f"{k}: {v}" for k, v in q["choices"].items()])
    return (
        f"{q['question']}\n\n"
        "ì„ íƒì§€:\n" + choices_str + "\n\n"
        f"ì§€ì‹œ: ì„ íƒì§€ {letter}ê°€ ì˜³ì€ ì´ìœ  3ê°€ì§€ë¥¼ ì œì‹œí•˜ê³ , ë‹¤ë¥¸ ì„ íƒì§€ì˜ ì•½ì  2ê°€ì§€ë¥¼ ì§šì–´ë¼."
    )

def make_bundle_system(max_sents: int) -> str:
    return (
        "ë„ˆëŠ” ë„¤ ëª…ì˜ í† ë¡ ì(A,B,C,D)ë¥¼ ë™ì‹œì— ì—°ê¸°í•œë‹¤.\n"
        "ê° í† ë¡ ìëŠ” ìì‹ ì˜ ì„ íƒì§€ë§Œ ì˜¹í˜¸í•˜ê³ , ë‹¤ë¥¸ ì„ íƒì§€ì˜ ì•½ì ì„ ìµœì†Œ 2ê°€ì§€ ì§€ì í•œë‹¤.\n"
        f"ê° ë°œì–¸ì€ í•œêµ­ì–´ë¡œ {max_sents}ë¬¸ì¥ ì´ë‚´.\n"
        "ì¶œë ¥ì€ **ì˜¤ì§ ì•„ë˜ JSON í•œ ë©ì–´ë¦¬**ë¡œë§Œ í•˜ë¼. ì½”ë“œíœìŠ¤/ì£¼ì„/ì„¤ëª… ê¸ˆì§€.\n"
        '{\n'
        '  "A": {"talk": "..."},\n'
        '  "B": {"talk": "..."},\n'
        '  "C": {"talk": "..."},\n'
        '  "D": {"talk": "..."}}\n'
    )

def make_bundle_user(q: dict) -> str:
    choices_str = "\n".join([f"{k}: {v}" for k, v in q["choices"].items()])
    return (
        "ë¬¸ì œ:\n"
        f"{q['question']}\n\n"
        "ì„ íƒì§€:\n" + choices_str + "\n\n"
        "ê° í† ë¡ ìì˜ ë°œì–¸ì„ ìœ„ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ë¼."
    )

# ================== ë©€í‹°ë³´ì´ìŠ¤ ìƒì„±ê¸° ==================
def generate_debate_bundle_single(model: str, q: dict, max_sents: int, temperature: float, top_p: float) -> Tuple[List[dict], List[str]]:
    """
    í•œ ë²ˆì˜ í˜¸ì¶œë¡œ A/B/C/D ë°œì–¸ì„ JSONìœ¼ë¡œ ë°›ì•„ debaters ë¦¬ìŠ¤íŠ¸ì™€ ë¬¸ìì—´ ë¸”ë¡ì„ ë°˜í™˜.
    """
    system_prompt = make_bundle_system(max_sents)
    user_msg = make_bundle_user(q)
    raw = chat_once(model, [{"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_msg}],
                    temperature=temperature, top_p=top_p)
    data = safe_json_loads(raw)
    debaters, debate_blocks = [], []
    if not isinstance(data, dict):
        # ì‹¤íŒ¨ ì‹œ ì•ˆì „í•˜ê²Œ ë¹ˆ í…ìŠ¤íŠ¸ë¡œ ì±„ì›€
        data = {k: {"talk": ""} for k in LETTERS}

    for i, letter in enumerate(LETTERS):
        content = str((data.get(letter) or {}).get("talk") or "")
        ai_role = f"AI{i+1}"
        debaters.append({"role": ai_role, "letter": letter, "content": content})
        debate_blocks.append(f"{ai_role} [{letter}]: {content}")
    return debaters, debate_blocks

# ================== í‰ê°€(ì €ì§€) ==================
def make_judge_payload(q: dict, debate_blocks: List[str], perm: List[str]) -> Tuple[str, str]:
    # ì„ íƒì§€/ë°œì–¸ì„ ê°™ì€ ë¬´ì‘ìœ„ ìˆœì„œë¡œ ì¬ë°°ì—´
    choices_lines = [f"{k}: {q['choices'][k]}" for k in perm]
    # debate_blocksëŠ” "AIi [L]: text" í˜•ì‹ì´ë¼ ê·¸ëŒ€ë¡œ ì„ì„ ìˆ˜ ìˆë„ë¡ ë§¤í•‘ ìƒì„±
    # ì—¬ê¸°ì„œëŠ” perm ìˆœì„œëŒ€ë¡œ í•„í„°ë§
    # ë¨¼ì € letterë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    letter2text = {}
    for line in debate_blocks:
        m = re.match(r"^(.+?)\s+\[([ABCD])\]:\s*(.*)$", line, re.S)
        if m:
            letter2text[m.group(2)] = (m.group(1), m.group(3))
    debate_lines = []
    for L in perm:
        role, txt = letter2text.get(L, (f"AI?{L}", ""))  # ì•ˆì „
        debate_lines.append(f"{role} [{L}]: {txt}")

    judge_instruction = (
        "ë„ˆëŠ” ì±„ì ê´€ì´ë‹¤.\n"
        "ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ `<answer>X</answer>` í•œ ì¤„ë§Œ ì¶œë ¥í•˜ë¼. (XëŠ” A/B/C/D ì¤‘ í•˜ë‚˜)\n"
        "ì„¤ëª…/ë²ˆì—­/ì¶”ê°€ í…ìŠ¤íŠ¸/ê°œí–‰/ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€. ì˜¤ì§ íƒœê·¸ 1ì¤„ë§Œ."
    )
    judge_user = (
        "ë¬¸ì œì™€ ì„ íƒì§€(ë¬´ì‘ìœ„ ìˆœì„œ):\n"
        f"Q: {q['question']}\n" +
        "\n".join(choices_lines) +
        "\n\në‹¤ìŒì€ ê° AIì˜ ì£¼ì¥(ë¬´ì‘ìœ„ ìˆœì„œ)ì´ë‹¤. ë…¼ë¦¬ì„±/ê·¼ê±°ì˜ êµ¬ì²´ì„±/ë°˜ë¡  ì²˜ë¦¬ ê´€ì ì—ì„œ ê°€ì¥ ì„¤ë“ë ¥ ìˆëŠ” í•˜ë‚˜ë¥¼ ê³ ë¥´ê³ , "
        "í˜•ì‹ ì§€ì‹œë¥¼ ì§€ì¼œì„œ ë‹µí•˜ë¼.\n\n" +
        "\n\n".join(debate_lines)
    )
    return judge_instruction, judge_user

def evaluate_one(qid: str, q: dict, debater_models: List[str], judge_model: str,
                 temperature: float, top_p: float, max_sents: int,
                 num_debaters: int, retry_judge: bool = True, domain: Optional[str] = None,
                 multi_voice: bool = True, single_debater_model: Optional[str] = None):
    """ë‹¨ì¼ ë¬¸í•­ í‰ê°€ -> dict ê²°ê³¼"""
    # ì•ˆì „ ë³´ì •/ê²€ì¦
    normalize_item_in_place(q)
    validate_item_or_stop(qid, q)

    # í† ë¡  ìƒì„±
    debaters, debate_blocks = [], []
    if multi_voice and single_debater_model:
        debaters, debate_blocks = generate_debate_bundle_single(
            single_debater_model, q, max_sents, temperature, top_p
        )
    else:
        # ê¸°ì¡´ ë°©ì‹: ê° í† ë¡ ì ê°œë³„ í˜¸ì¶œ
        for i, letter in enumerate(LETTERS):
            ai_role = f"AI{i+1}"
            claim = q["choices"][letter]
            system_prompt = make_debater_system(ai_role, letter, claim, max_sents)
            user_msg = make_debater_user(q, letter)
            model_for_role = debater_models[i % num_debaters]
            try:
                content = chat_once(
                    model_for_role,
                    [{"role": "system", "content": system_prompt},
                     {"role": "user", "content": user_msg}],
                    temperature=temperature, top_p=top_p,
                )
            except Exception as e:
                content = f"[ì˜¤ë¥˜] ëª¨ë¸ ì‘ë‹µ ì‹¤íŒ¨: {e}"
            debaters.append({"role": ai_role, "letter": letter, "content": content})
            debate_blocks.append(f"{ai_role} [{letter}]: {content}")

    # ì €ì§€
    perm = LETTERS[:]
    random.shuffle(perm)
    judge_instruction, judge_user = make_judge_payload(q, debate_blocks, perm)

    try:
        judge_raw = chat_once(
            judge_model,
            [{"role": "system", "content": judge_instruction},
             {"role": "user", "content": judge_user}],
            temperature=0.0, top_p=1.0,
            stop=["\n"],  # í•œ ì¤„ ê°•ì œ
        )
        judge_choice = extract_choice(judge_raw)
        if not judge_choice and retry_judge:
            judge_raw2 = chat_once(
                judge_model,
                [{"role": "system", "content": judge_instruction + "\në°˜ë“œì‹œ ì˜ˆ: <answer>C</answer> í˜•ì‹."},
                 {"role": "user", "content": judge_user}],
                temperature=0.0, top_p=1.0, stop=["\n"],
            )
            jc2 = extract_choice(judge_raw2)
            if jc2:
                judge_choice, judge_raw = jc2, judge_raw2
    except Exception as e:
        judge_choice, judge_raw = "", f"[ì˜¤ë¥˜] Judge ëª¨ë¸ ì‹¤íŒ¨: {e}"

    correct = (judge_choice == q["answer"])
    # debatersë¥¼ í¼ì³ì„œ í…ìŠ¤íŠ¸ ì €ì¥
    a_text = next((d["content"] for d in debaters if d["letter"] == "A"), "")
    b_text = next((d["content"] for d in debaters if d["letter"] == "B"), "")
    c_text = next((d["content"] for d in debaters if d["letter"] == "C"), "")
    d_text = next((d["content"] for d in debaters if d["letter"] == "D"), "")

    return {
        "qid": qid,
        "domain": domain or "",
        "topic": q.get("topic", ""),
        "question": q["question"],
        "gold": q["answer"],
        "judge": judge_choice or "",
        "correct": bool(correct),
        "judge_raw": judge_raw,
        "A_text": a_text,
        "B_text": b_text,
        "C_text": c_text,
        "D_text": d_text,
        "perm": "".join(perm),  # ë¬´ì‘ìœ„ ì œì‹œ ìˆœì„œ(ë¡œê·¸ìš©)
    }

# ================== í† í”½(ë¬¸ì œ ìœ í˜•) í•„í„° ==================
def topic_of(q: dict) -> str:
    t = (q.get("topic") or "").strip()
    return t if t else "(ë¯¸ë¶„ë¥˜)"

def list_topics(mmlu_data: dict) -> List[str]:
    return sorted({topic_of(q) for q in mmlu_data.values()})

def filter_qids_by_topic(mmlu_data: dict, qids: List[str], picked_topics: List[str]) -> List[str]:
    picked = set(picked_topics)
    return [qid for qid in qids if topic_of(mmlu_data[qid]) in picked]

# ================== ì•± ==================
st.set_page_config(page_title="MMLU Debate Evaluation", layout="wide")
st.sidebar.title("ğŸ§  MMLU í† ë¡  í‰ê°€")

# ë°ì´í„° ë¡œë“œ
mmlu_data, domain_index, qid2domain = load_questions()
all_qids = list(mmlu_data.keys())
if not all_qids:
    st.error("ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤. JSON íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”."); st.stop()

# í† í”½(ë¬¸ì œ ìœ í˜•) í•„í„°
st.sidebar.markdown("### ğŸ—‚ ë¬¸ì œ ìœ í˜•(í† í”½) í•„í„°")
all_topics = list_topics(mmlu_data)
picked_topics = st.sidebar.multiselect("ìœ í˜• ì„ íƒ(ë³µìˆ˜ ê°€ëŠ¥)", all_topics, default=all_topics)

# Ollama ì¤€ë¹„
check_ollama()
try:
    model_list = [m["model"] for m in ollama.list()["models"]]
except Exception as e:
    st.error(f"Ollama ëª¨ë¸ ëª©ë¡ ì˜¤ë¥˜: {e}"); st.stop()
if not model_list:
    st.error("ì„¤ì¹˜ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. `ollama pull mistral` ë“±ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”."); st.stop()

# ê³µí†µ í•˜ì´í¼íŒŒë¼ë¯¸í„°
st.sidebar.markdown("### âš™ï¸ ê³µí†µ ì„¤ì •")
temperature = st.sidebar.slider("temperature", 0.0, 1.5, 0.2, 0.1)
top_p = st.sidebar.slider("top_p", 0.1, 1.0, 0.9, 0.05)
max_sents = st.sidebar.slider("ë°œì–¸ ë¬¸ì¥ ìˆ˜(ê¶Œì¥ ìµœëŒ€)", 3, 8, 6, 1)

# ëª¨ë“œ ì „í™˜: 1ì¸ ë‹¤ì—­(ë©€í‹°ë³´ì´ìŠ¤)
st.sidebar.markdown("---")
multi_voice = st.sidebar.checkbox("âš¡ 1ì¸ ë‹¤ì—­(í•œ ëª¨ë¸ë¡œ A/B/C/D ìƒì„±, 1ì½œ)", value=True)

# ëª¨ë¸ ì„ íƒ
st.sidebar.markdown("### ğŸ¤– í† ë¡ ì & ì €ì§€ ëª¨ë¸")
if multi_voice:
    single_debater_model = st.sidebar.selectbox("í† ë¡ ì(1ì¸ ë‹¤ì—­) ëª¨ë¸", model_list, key="single_deb_model")
    debater_models = [single_debater_model]  # placeholder
    num_debaters = 1
else:
    num_debaters = st.sidebar.slider("í† ë¡ ì ìˆ˜", 1, 4, 4)
    debater_models = [st.sidebar.selectbox(f"í† ë¡ ì ëª¨ë¸ {i+1}", model_list, key=f"deb_model_{i+1}") for i in range(num_debaters)]
    single_debater_model = None

judge_default = model_list.index("mistral") if "mistral" in model_list else 0
judge_model = st.sidebar.selectbox("Judge ëª¨ë¸ ì„ íƒ", model_list, index=judge_default)
st.sidebar.caption("1ì¸ ë‹¤ì—­: í† ë¡ ì ìƒì„± 1ì½œ + ì €ì§€ 1ì½œ. ê¸°ì¡´ ë°©ì‹: í† ë¡ ì ìµœëŒ€ 4ì½œ + ì €ì§€ 1ì½œ.")

# ì‹¤í–‰ ëª¨ë“œ
mode = st.radio("ì‹¤í–‰ ëª¨ë“œ ì„ íƒ", ["ë‹¨ì¼ ë¬¸ì œ", "ì „ì²´ í‰ê°€"], horizontal=True)

# ---------------- ë‹¨ì¼ ë¬¸ì œ ----------------
if mode == "ë‹¨ì¼ ë¬¸ì œ":
    filtered_qids = filter_qids_by_topic(mmlu_data, all_qids, picked_topics)
    if not filtered_qids:
        st.warning("ì„ íƒëœ í† í”½ì— í•´ë‹¹í•˜ëŠ” ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ í† í”½ì„ ì¡°ì •í•˜ì„¸ìš”."); st.stop()

    topics_for_pick = sorted({topic_of(mmlu_data[qid]) for qid in filtered_qids})
    chosen_topic = st.selectbox("ë¬¸ì œ ìœ í˜•(í† í”½)", topics_for_pick)
    topic_qids = [qid for qid in filtered_qids if topic_of(mmlu_data[qid]) == chosen_topic]

    qid = st.selectbox("ë¬¸ì œ ì„ íƒ", topic_qids, key="single_qid")
    q = mmlu_data[qid]

    normalize_item_in_place(q)
    validate_item_or_stop(qid, q)

    st.caption(f"ìœ í˜•: {topic_of(q)}")
    st.markdown(f"### â“ {q['question']}")
    st.markdown("**ì„ íƒì§€**")
    for k in LETTERS:
        st.markdown(f"- **{k}**: {q['choices'][k]}")

    if st.button("ğŸš€ í† ë¡  ì‹œì‘ + ì €ì§€ ì±„ì "):
        with st.spinner("í† ë¡  ìƒì„± ì¤‘..."):
            if multi_voice and single_debater_model:
                debaters, debate_blocks = generate_debate_bundle_single(
                    single_debater_model, q, max_sents, temperature, top_p
                )
            else:
                debaters, debate_blocks = [], []
                for i, letter in enumerate(LETTERS):
                    ai_role = f"AI{i+1}"
                    claim = q["choices"][letter]
                    system_prompt = make_debater_system(ai_role, letter, claim, max_sents)
                    user_msg = make_debater_user(q, letter)
                    model_for_role = debater_models[i % max(1, num_debaters)]
                    try:
                        content = chat_once(
                            model_for_role,
                            [{"role": "system", "content": system_prompt},
                             {"role": "user", "content": user_msg}],
                            temperature=temperature, top_p=top_p,
                        )
                    except Exception as e:
                        content = f"[ì˜¤ë¥˜] ëª¨ë¸ ì‘ë‹µ ì‹¤íŒ¨: {e}"
                    debaters.append({"role": ai_role, "letter": letter, "content": content})
                    debate_blocks.append(f"{ai_role} [{letter}]: {content}")

        st.subheader("ğŸ’¬ AI ë°œì–¸")
        for d in debaters:
            st.markdown(f"**{d['role']} ({d['letter']} ì£¼ì¥)**")
            st.info(d["content"])

        # ì €ì§€
        st.subheader("âš–ï¸ Judge ëª¨ë¸ íŒë‹¨")
        perm = LETTERS[:]
        random.shuffle(perm)
        judge_instruction, judge_user = make_judge_payload(q, debate_blocks, perm)

        with st.spinner("Judge í‰ê°€ ì¤‘..."):
            final_choice, judge_raw = "", ""
            for attempt in range(3):
                try:
                    judge_raw = chat_once(
                        judge_model,
                        [
                            {"role": "system", "content": judge_instruction},
                            {"role": "user", "content": judge_user if attempt == 0
                             else judge_user + "\n\nì˜¤ì§ í•œ ì¤„ë¡œ `<answer>X</answer>`ë§Œ ì¶œë ¥."},
                        ],
                        temperature=0.0, top_p=1.0, stop=["\n"],
                    )
                except Exception as e:
                    judge_raw = f"[ì˜¤ë¥˜] Judge ëª¨ë¸ ì‹¤íŒ¨: {e}"
                    break
                final_choice = extract_choice_strict(judge_raw)
                if final_choice:
                    break

        if not final_choice:
            st.error("Judge ì¶œë ¥ì—ì„œ A/B/C/Dë¥¼ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.markdown(f"**Judge ì„ íƒ:** {final_choice}")
            st.markdown(f"**ì •ë‹µ:** {q['answer']}")
            st.success("ì •ë‹µê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤! âœ…") if final_choice == q["answer"] else st.error("ì •ë‹µê³¼ ë¶ˆì¼ì¹˜! âŒ")

# ---------------- ì „ì²´ í‰ê°€ ----------------
else:
    st.markdown("### ğŸ“š ì „ì²´ í‰ê°€ ì„¤ì •")

    filtered_qids = filter_qids_by_topic(mmlu_data, all_qids, picked_topics)
    if not filtered_qids:
        st.warning("ì„ íƒëœ í† í”½ì— í•´ë‹¹í•˜ëŠ” ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ í† í”½ì„ ì¡°ì •í•˜ì„¸ìš”."); st.stop()

    random_order = st.checkbox("ë¬¸ì œ ìˆœì„œ ì„ê¸°", value=False)
    seed = st.number_input("ëœë¤ ì‹œë“œ", value=42, step=1)
    max_count = st.slider("í‰ê°€í•  ë¬¸ì œ ê°œìˆ˜", 1, len(filtered_qids), len(filtered_qids))
    show_logs = st.checkbox("ë¬¸í•­ë³„ ìƒì„¸ ë¡œê·¸ í‘œì‹œ", value=False)

    selected_qids = filtered_qids.copy()
    if random_order:
        random.Random(seed).shuffle(selected_qids)
    selected_qids = selected_qids[:max_count]

    if st.button("ğŸ§ª ì „ì²´ í‰ê°€ ì‹œì‘"):
        results, start_time = [], time.time()
        progress = st.progress(0, text="ì‹œì‘ ì¤‘...")

        for idx, qid in enumerate(selected_qids, start=1):
            q = mmlu_data[qid]
            normalize_item_in_place(q)
            validate_item_or_stop(qid, q)

            progress.progress(idx / max_count, text=f"{idx}/{max_count} í‰ê°€ ì¤‘: {qid}")
            res = evaluate_one(
                qid=qid, q=q,
                debater_models=debater_models,
                judge_model=judge_model,
                temperature=temperature, top_p=top_p,
                max_sents=max_sents, num_debaters=(num_debaters if not multi_voice else 1),
                retry_judge=True, domain=qid2domain.get(qid),
                multi_voice=multi_voice, single_debater_model=single_debater_model
            )
            results.append(res)

            if show_logs:
                with st.expander(f"[{idx}] {qid} | ë¶„ì•¼: {qid2domain.get(qid, q.get('topic',''))} | ì •ë‹µ: {res['gold']} | Judge: {res['judge']} | {'âœ…' if res['correct'] else 'âŒ'}"):
                    st.write(q["question"])
                    st.write({k: v for k, v in q["choices"].items()})
                    st.markdown("**Judge ì›ë¬¸ ì¶œë ¥**"); st.code(res["judge_raw"])
                    st.markdown("**AI1 (A) ë°œì–¸**"); st.info(res["A_text"])
                    st.markdown("**AI2 (B) ë°œì–¸**"); st.info(res["B_text"])
                    st.markdown("**AI3 (C) ë°œì–¸**"); st.info(res["C_text"])
                    st.markdown("**AI4 (D) ë°œì–¸**"); st.info(res["D_text"])

        total_time = time.time() - start_time
        progress.progress(1.0, text="ì™„ë£Œ")

        # ìš”ì•½
        df = pd.DataFrame(results)
        st.markdown("## ğŸ“ˆ ê²°ê³¼ ìš”ì•½")
        if df.empty:
            st.warning("ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."); st.stop()
        acc = df["correct"].mean()
        c1, c2, c3 = st.columns(3)
        c1.metric("ì´ ë¬¸í•­", len(df))
        c2.metric("ì •í™•ë„(%)", f"{acc*100:.1f}")
        c3.metric("ì´ ì†Œìš”ì‹œê°„(ì´ˆ)", f"{total_time:.1f}")

        # ë¶„ì•¼ë³„/í† í”½ë³„ ì •í™•ë„
        st.markdown("### ğŸ§­ ë¶„ì•¼ë³„ ì •í™•ë„ (domain)")
        if "domain" in df.columns:
            dom_acc = df.groupby("domain")["correct"].mean().sort_values(ascending=False)
            st.dataframe(dom_acc.to_frame("accuracy").assign(accuracy=lambda x: (x["accuracy"]*100).round(1)))

        st.markdown("### ğŸ§­ ì£¼ì œë³„ ì •í™•ë„ (topic)")
        if "topic" in df.columns:
            topic_acc = df.groupby("topic")["correct"].mean().sort_values(ascending=False)
            st.dataframe(topic_acc.to_frame("accuracy").assign(accuracy=lambda x: (x["accuracy"]*100).round(1)))

        # í˜¼ë™ í–‰ë ¬
        st.markdown("### ğŸ” í˜¼ë™ í–‰ë ¬ (Judge vs ì •ë‹µ)")
        cm = pd.crosstab(df["gold"], df["judge"], dropna=False).reindex(index=LETTERS, columns=LETTERS, fill_value=0)
        st.dataframe(cm)

        # CSV ë‹¤ìš´ë¡œë“œ
        st.markdown("### â¬‡ï¸ ê²°ê³¼ ì €ì¥")
        csv = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="mmlu_batch_results.csv", mime="text/csv")
