

import os
import re
import json
import time
import random
from typing import Dict, List, Tuple, Optional

import pandas as pd
import streamlit as st
import ollama
from utils import check_ollama

# ================== ìƒìˆ˜/ì „ì—­ ==================
LETTERS = ["A", "B", "C", "D"]

# ================== ê³µìš© ìœ í‹¸ ==================
def clean_surrogates(text: str) -> str:
    return re.sub(r'[\ud800-\udfff]', '', text or "")

def safe_json_loads(payload: str) -> Optional[dict]:
    """
    ëª¨ë¸ì´ ì½”ë“œíœìŠ¤ë‚˜ ì•ë’¤ ì¡ìŒì„ ë§ë¶™ì˜€ì„ ë•Œë„ JSONë§Œ ì¶”ì¶œí•´ì„œ íŒŒì‹±.
    """
    if not payload:
        return None
    m = re.search(r"\{.*\}", payload, re.S)
    if not m:
        return None
    try:
        return json.loads(m.group(0))
    except Exception:
        return None

# ---- ë°œì–¸ ì¶”ì¶œ ë³´ê°• ----
def _extract_talk(value) -> str:
    """ëª¨ë¸ ì¶œë ¥ì—ì„œ ë°œì–¸ í…ìŠ¤íŠ¸ë¥¼ ìµœëŒ€í•œ ì•ˆì „í•˜ê²Œ ë½‘ì•„ë‚¸ë‹¤."""
    if isinstance(value, str):
        return value.strip()
    if isinstance(value, dict):
        for k in ("talk", "speech", "content", "text", "message"):
            v = value.get(k)
            if isinstance(v, str):
                return v.strip()
        parts = [str(v).strip() for v in value.values() if isinstance(v, (str, int, float))]
        if parts:
            return " ".join(parts)
    if isinstance(value, list):
        parts = [str(x).strip() for x in value if isinstance(x, (str, int, float))]
        if parts:
            return " ".join(parts)
    return ""

def _normalize_debate_json(data: dict) -> Dict[str, str]:
    """
    í—ˆìš© í˜•íƒœ:
      1) {"A":{"talk":"..."}, "B":{"talk":"..."}, ...}
      2) {"A":"...", "B":"...", ...}
      3) í‚¤ ëŒ€ì†Œë¬¸ì ì„ì„
    ë°˜í™˜: {"A": str, "B": str, "C": str, "D": str}
    """
    if not isinstance(data, dict):
        return {k: "" for k in LETTERS}
    upper = {str(k).upper(): v for k, v in data.items()}
    out = {}
    for L in LETTERS:
        v = upper.get(L)
        out[L] = _extract_talk(v) if v is not None else ""
    return out

@st.cache_data(show_spinner=False)
def load_questions():
    """
    ë„ë©”ì¸(ë¶„ì•¼) -> {qid: item} í˜•íƒœ/ê¸°ì¡´ í‰íƒ„ í˜•íƒœ ëª¨ë‘ ì§€ì›.
    ë°˜í™˜: (flat_questions, domain_index, qid2domain)
    """
    candidates = [
        "pages/mmlu_debate_questions.json",
        "mmlu_debate_questions.json",
        r"C:\Users\USER\ollama\pages\mmlu_debate_questions.json",
    ]
    for p in candidates:
        if os.path.exists(p):
            with open(p, "r", encoding="utf-8") as f:
                raw = json.load(f)

            def looks_like_question(d: dict) -> bool:
                return isinstance(d, dict) and {"question", "choices", "answer"}.issubset(d.keys())

            is_nested = all(isinstance(v, dict) for v in raw.values()) and not any(
                looks_like_question(v) for v in raw.values()
            )

            flat, domain_index, qid2domain = {}, {}, {}
            if is_nested:
                for domain, items in raw.items():
                    if not isinstance(items, dict):
                        continue
                    domain_index.setdefault(domain, [])
                    for qid, item in items.items():
                        if not looks_like_question(item):
                            continue
                        flat[qid] = item
                        flat[qid]["topic"] = item.get("topic") or domain
                        domain_index[domain].append(qid)
                        qid2domain[qid] = domain
            else:
                for qid, item in raw.items():
                    if not looks_like_question(item):
                        continue
                    flat[qid] = item
                    dom = item.get("topic", "Misc")
                    domain_index.setdefault(dom, []).append(qid)
                    qid2domain[qid] = dom
                    flat[qid]["topic"] = flat[qid].get("topic", dom)
            return flat, domain_index, qid2domain

    st.error("mmlu_debate_questions.json íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìœ„ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

def extract_choice_strict(text: str) -> str:
    """
    Judge ì „ìš©: íƒœê·¸ í•œ ì¤„ or 'ì •ë‹µ/answer/final: X' í•œ ì¤„ë§Œ ì¸ì •.
    """
    t = (text or "").strip()
    m = re.search(r"<answer>\s*([ABCD])\s*</answer>", t, re.I)
    if m:
        return m.group(1).upper()
    m = re.fullmatch(r"(?:ì •ë‹µ|answer|final)\s*(?:is|:|=)?\s*([ABCD])\s*", t, re.I)
    if m:
        return m.group(1).upper()
    return ""

def extract_choice(text: str) -> str:
    t = (text or "").strip()
    m = re.search(r"<answer>\s*([ABCD])\s*</answer>", t, re.I)
    if m: return m.group(1).upper()
    m = re.search(r"(ì •ë‹µ|answer|final)\s*(is|:|=)?\s*([ABCD])\b", t, re.I)
    if m: return m.group(3).upper()
    for line in t.splitlines():
        m = re.match(r"^\s*[\(\[\{<]?\s*([ABCD])\s*[\)\]\}>]?\s*$", line.strip(), re.I)
        if m: return m.group(1).upper()
    m = re.findall(r"(?<![A-Z])([ABCD])(?![A-Z])", t.upper())
    return m[0] if m else ""

def normalize_item_in_place(q: dict):
    # í‚¤ ì´ë¦„ ë³´ì •
    if "question" not in q and "prompt" in q:
        q["question"] = q["prompt"]
    if "choices" not in q and "answers" in q:
        q["choices"] = q["answers"]
    if "answer" not in q and "gold" in q:
        q["answer"] = q["gold"]

    # ì„ íƒì§€ í˜•íƒœ ë³´ì • â†’ ABCD dict
    if isinstance(q.get("choices"), list):
        q["choices"] = {LETTERS[i]: q["choices"][i] for i in range(min(4, len(q["choices"])))}
    elif isinstance(q.get("choices"), dict):
        ks = list(q["choices"].keys())
        if any(k not in LETTERS for k in ks):
            vals = list(q["choices"].values())
            q["choices"] = {LETTERS[i]: vals[i] for i in range(min(4, len(vals)))}

    # topic ê¸°ë³¸
    if not q.get("topic"):
        q["topic"] = "(ë¯¸ë¶„ë¥˜)"

def validate_item_or_stop(qid: str, q: dict):
    need = ["question", "choices", "answer"]
    miss = [k for k in need if k not in q]
    if miss:
        st.error(f"[{qid}] ë¬¸í•­ í‚¤ ëˆ„ë½: {miss}")
        st.json(q); st.stop()
    if not isinstance(q["choices"], dict):
        st.error(f"[{qid}] choicesê°€ dictê°€ ì•„ë‹™ë‹ˆë‹¤.")
        st.json(q); st.stop()
    # ì„ íƒì§€ëŠ” A/B/C/Dë§Œ ìœ ì§€
    for k in list(q["choices"].keys()):
        if k not in LETTERS:
            del q["choices"][k]
    if len(q["choices"]) < 2:
        st.error(f"[{qid}] ì„ íƒì§€ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        st.json(q); st.stop()
    # 4ì§€ì„ ë‹¤ ê°€ì •
    if any(k not in q["choices"] for k in LETTERS):
        st.error(f"[{qid}] í† ë¡  ëª¨ë“œìš© 4ì§€ì„ ë‹¤(ABCD) í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        st.json(q); st.stop()

# ================== Ollama ë˜í¼ ==================
def chat_once(model: str, messages: list, temperature: float, top_p: float,
              keep_alive: str = "5m", **options) -> str:
    """
    í•œ ë²ˆ í˜¸ì¶œ. keep_aliveë¡œ ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ìœ ì§€í•´ ë°˜ë³µ í˜¸ì¶œ ë¹„ìš©ì„ ì¤„ì„.
    ì¶”ê°€ ì˜µì…˜: num_ctx, seed, top_k, repeat_penalty ë“± ì „ë‹¬ ê°€ëŠ¥.
    """
    opts = {
        "temperature": float(temperature),
        "top_p": float(top_p),
        "keep_alive": keep_alive,
    }
    opts.update(options or {})
    res = ollama.chat(model=model, messages=messages, stream=False, options=opts)
    return clean_surrogates(res.get("message", {}).get("content", ""))

# ================== í† ë¡  í”„ë¡¬í”„íŠ¸ ==================
def make_debater_system(ai_role: str, letter: str, claim: str, max_sents: int) -> str:
    return (
        f"ì—­í• : {ai_role}\n"
        f"ë‹´ë‹¹ ì„ íƒì§€: {letter}\n"
        f"ëª©í‘œ: ì˜¤ì§ ì„ íƒì§€ {letter}({claim})ê°€ ì˜³ë‹¤ê³  ê°•ë ¥íˆ ì˜¹í˜¸í•˜ë¼.\n\n"
        "ê·œì¹™:\n"
        f"- '{letter}' ì™¸ ë‹¤ë¥¸ ì„ íƒì§€ê°€ ë” ë‚«ë‹¤ê³  ë§í•˜ì§€ ë§ˆë¼.\n"
        "- 'ì •ë‹µì€ C' ê°™ì€ í‘œí˜„ ê¸ˆì§€.\n"
        "- ë°˜ëŒ€ ì„ íƒì§€ì˜ ì•½ì ì„ ìµœì†Œ 2ê°€ì§€ ì§€ì í•˜ë¼.\n"
        f"- í•œêµ­ì–´ë¡œë§Œ, {max_sents}ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ.\n"
    )

def make_debater_user(q: dict, letter: str) -> str:
    choices_str = "\n".join([f"{k}: {v}" for k, v in q["choices"].items()])
    return (
        f"{q['question']}\n\n"
        "ì„ íƒì§€:\n" + choices_str + "\n\n"
        f"ì§€ì‹œ: ì„ íƒì§€ {letter}ê°€ ì˜³ì€ ì´ìœ  3ê°€ì§€ë¥¼ ì œì‹œí•˜ê³ , ë‹¤ë¥¸ ì„ íƒì§€ì˜ ì•½ì  2ê°€ì§€ë¥¼ ì§šì–´ë¼."
    )

def make_bundle_system(max_sents: int) -> str:
    return (
        "ë„ˆëŠ” ë„¤ ëª…ì˜ í† ë¡ ì(A,B,C,D)ë¥¼ ë™ì‹œì— ì—°ê¸°í•œë‹¤.\n"
        "ê° í† ë¡ ìëŠ” ìì‹ ì˜ ì„ íƒì§€ë§Œ ì˜¹í˜¸í•˜ê³ , ë‹¤ë¥¸ ì„ íƒì§€ì˜ ì•½ì ì„ ìµœì†Œ 2ê°€ì§€ ì§€ì í•œë‹¤.\n"
        f"ê° ë°œì–¸ì€ í•œêµ­ì–´ë¡œ {max_sents}ë¬¸ì¥ ì´ë‚´.\n"
        "ì¶œë ¥ì€ **ì˜¤ì§ í•˜ë‚˜ì˜ JSON ê°ì²´**ë¡œ í•˜ê³ , ì½”ë“œíœìŠ¤/ì„¤ëª… ê¸ˆì§€.\n"
        'ê¶Œì¥ í˜•ì‹: {"A":{"talk":"..."}, "B":{"talk":"..."}, "C":{"talk":"..."}, "D":{"talk":"..."}}\n'
        'í—ˆìš© í˜•ì‹: {"A":"...", "B":"...", "C":"...", "D":"..."}\n'
    )

def make_bundle_user(q: dict) -> str:
    choices_str = "\n".join([f"{k}: {v}" for k, v in q["choices"].items()])
    return (
        "ë¬¸ì œ:\n"
        f"{q['question']}\n\n"
        "ì„ íƒì§€:\n" + choices_str + "\n\n"
        "ìœ„ JSON í˜•ì‹ìœ¼ë¡œ ê° í† ë¡ ìì˜ ë°œì–¸ì„ ìƒì„±í•˜ë¼."
    )

# ================== ë©€í‹°ë³´ì´ìŠ¤ ìƒì„±ê¸° ==================
def generate_debate_bundle_single(model: str, q: dict, max_sents: int,
                                  temperature: float, top_p: float,
                                  num_ctx: int = 8192, seed: Optional[int] = None,
                                  top_k: Optional[int] = None, repeat_penalty: Optional[float] = None
                                  ) -> Tuple[List[dict], List[str]]:
    """
    í•œ ë²ˆì˜ í˜¸ì¶œë¡œ A/B/C/D ë°œì–¸ì„ JSONìœ¼ë¡œ ë°›ì•„ debaters ë¦¬ìŠ¤íŠ¸ì™€ ë¬¸ìì—´ ë¸”ë¡ì„ ë°˜í™˜.
    ì¤‘ì²©Â·í‰í‰ JSON ëª¨ë‘ í—ˆìš©.
    """
    system_prompt = make_bundle_system(max_sents)
    user_msg = make_bundle_user(q)
    extra = {}
    if num_ctx: extra["num_ctx"] = int(num_ctx)
    if seed is not None: extra["seed"] = int(seed)
    if top_k is not None: extra["top_k"] = int(top_k)
    if repeat_penalty is not None: extra["repeat_penalty"] = float(repeat_penalty)

    raw = chat_once(
        model,
        [{"role": "system", "content": system_prompt},
         {"role": "user", "content": user_msg}],
        temperature=temperature, top_p=top_p, **extra
    )
    data = safe_json_loads(raw)
    talks = _normalize_debate_json(data)
    debaters, debate_blocks = [], []
    for i, letter in enumerate(LETTERS):
        ai_role = f"AI{i+1}"
        content = talks.get(letter, "")
        debaters.append({"role": ai_role, "letter": letter, "content": content})
        debate_blocks.append(f"{ai_role} [{letter}]: {content}")
    return debaters, debate_blocks

# ================== ì €ì§€ í”„ë¡¬í”„íŠ¸(íƒœê·¸ ëª¨ë“œ) ==================
def make_judge_payload(q: dict, debate_blocks: List[str], perm: List[str]) -> Tuple[str, str]:
    # ì„ íƒì§€/ë°œì–¸ì„ ê°™ì€ ë¬´ì‘ìœ„ ìˆœì„œë¡œ ì¬ë°°ì—´
    choices_lines = [f"{k}: {q['choices'][k]}" for k in perm]
    letter2text = {}
    for line in debate_blocks:
        m = re.match(r"^(.+?)\s+\[([ABCD])\]:\s*(.*)$", line, re.S)
        if m:
            letter2text[m.group(2)] = (m.group(1), m.group(3))
    debate_lines = []
    for L in perm:
        role, txt = letter2text.get(L, (f"AI?{L}", ""))  # ì•ˆì „
        debate_lines.append(f"{role} [{L}]: {txt}")

    judge_instruction = (
        "ë„ˆëŠ” ì±„ì ê´€ì´ë‹¤.\n"
        "ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ `<answer>X</answer>` í•œ ì¤„ë§Œ ì¶œë ¥í•˜ë¼. (XëŠ” A/B/C/D ì¤‘ í•˜ë‚˜)\n"
        "ì„¤ëª…/ë²ˆì—­/ì¶”ê°€ í…ìŠ¤íŠ¸/ê°œí–‰/ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€. ì˜¤ì§ íƒœê·¸ 1ì¤„ë§Œ."
    )
    judge_user = (
        "ë¬¸ì œì™€ ì„ íƒì§€(ë¬´ì‘ìœ„ ìˆœì„œ):\n"
        f"Q: {q['question']}\n" +
        "\n".join(choices_lines) +
        "\n\në‹¤ìŒì€ ê° AIì˜ ì£¼ì¥(ë¬´ì‘ìœ„ ìˆœì„œ)ì´ë‹¤. ë…¼ë¦¬ì„±/ê·¼ê±°ì˜ êµ¬ì²´ì„±/ë°˜ë¡  ì²˜ë¦¬ ê´€ì ì—ì„œ ê°€ì¥ ì„¤ë“ë ¥ ìˆëŠ” í•˜ë‚˜ë¥¼ ê³ ë¥´ê³ , "
        "í˜•ì‹ ì§€ì‹œë¥¼ ì§€ì¼œì„œ ë‹µí•˜ë¼.\n\n" +
        "\n\n".join(debate_lines)
    )
    return judge_instruction, judge_user

# ================== (ì„ íƒ) ì ìˆ˜ JSON ì €ì§€ ëª¨ë“œ ==================
def make_judge_scores_payload(q: dict, debate_blocks: List[str], perm: List[str]) -> Tuple[str, str]:
    choices_lines = [f"{k}: {q['choices'][k]}" for k in perm]
    letter2text = {}
    for line in debate_blocks:
        m = re.match(r"^(.+?)\s+\[([ABCD])\]:\s*(.*)$", line, re.S)
        if m:
            letter2text[m.group(2)] = (m.group(1), m.group(3))
    debate_lines = []
    for L in perm:
        role, txt = letter2text.get(L, (f"AI?{L}", ""))  # ì•ˆì „
        debate_lines.append(f"{role} [{L}]: {txt}")

    judge_instruction = (
        "ë„ˆëŠ” ì±„ì ê´€ì´ë‹¤.\n"
        "ê° ì„ íƒì§€ A/B/C/Dì— ëŒ€í•´ 0~100 ì ìˆ˜ë¥¼ ë§¤ê²¨ë¼(ë†’ì„ìˆ˜ë¡ ì„¤ë“ë ¥). "
        "ì¶œë ¥ì€ ì˜¤ì§ ì•„ë˜ JSON í•œ ì¤„ë§Œ í—ˆìš©(ì½”ë“œíœìŠ¤/ì£¼ì„/ë¬¸ì¥ ê¸ˆì§€).\n"
        '{"A": 0, "B": 0, "C": 0, "D": 0}'
    )
    judge_user = (
        "ë¬¸ì œì™€ ì„ íƒì§€(ë¬´ì‘ìœ„ ìˆœì„œ):\n"
        f"Q: {q['question']}\n" + "\n".join(choices_lines) +
        "\n\në‹¤ìŒì€ ê° AIì˜ ì£¼ì¥(ë¬´ì‘ìœ„ ìˆœì„œ)ì´ë‹¤. ì ìˆ˜ë§Œ JSONìœ¼ë¡œ ë‚´ë¼.\n\n" +
        "\n\n".join(debate_lines)
    )
    return judge_instruction, judge_user

def _parse_score_json(payload: str) -> Dict[str, float]:
    d = safe_json_loads(payload) or {}
    out = {}
    for k in LETTERS:
        v = d.get(k)
        try:
            out[k] = float(v)
        except Exception:
            out[k] = float("-inf")
    return out

def run_one_judge_vote(judge_model_name: str, q: dict, debate_blocks: List[str],
                       mode_scores: bool, num_ctx: int, seed: int) -> Tuple[str, str]:
    """ë‹¨í‘œ ëª¨ë“œ. mode_scores=Trueë©´ JSON ì ìˆ˜, Falseë©´ íƒœê·¸ 1ì¤„."""
    perm = LETTERS[:]
    random.shuffle(perm)

    if mode_scores:
        instr, user = make_judge_scores_payload(q, debate_blocks, perm)
        raw = chat_once(
            judge_model_name,
            [{"role": "system", "content": instr}, {"role": "user", "content": user}],
            temperature=0.0, top_p=1.0, num_ctx=num_ctx, seed=seed,
        )
        scores = _parse_score_json(raw)
        best = max(LETTERS, key=lambda L: (scores.get(L, float("-inf")), L))
        return best, raw
    else:
        instr, user = make_judge_payload(q, debate_blocks, perm)
        raw = chat_once(
            judge_model_name,
            [{"role": "system", "content": instr}, {"role": "user", "content": user}],
            temperature=0.0, top_p=1.0, num_ctx=num_ctx, seed=seed, stop=["\n"],
        )
        pick = extract_choice_strict(raw) or extract_choice(raw)
        if pick not in LETTERS:
            raw2 = chat_once(
                judge_model_name,
                [{"role": "system", "content": instr + "\në°˜ë“œì‹œ ì˜ˆ: <answer>C</answer> í˜•ì‹."},
                 {"role": "user", "content": user}],
                temperature=0.0, top_p=1.0, num_ctx=num_ctx, seed=seed + 999, stop=["\n"],
            )
            pick = extract_choice_strict(raw2) or extract_choice(raw2)
            raw = raw2 if pick in LETTERS else raw
        return (pick if pick in LETTERS else ""), raw

# ================== NEW: 1ì¸Nì—­ ë²ˆë“¤ ì €ì§€ ==================
def make_judge_bundle_payload(q: dict, debate_blocks: List[str], perm: List[str], size: int = 5) -> Tuple[str, str]:
    """J1..J{size} ì‹¬ì‚¬ìœ„ì›ì´ ë™ì‹œì— í•œ í‘œì”©(A/B/C/D) ë½‘ì•„ JSONìœ¼ë¡œë§Œ ì¶œë ¥."""
    choices_lines = [f"{k}: {q['choices'][k]}" for k in perm]

    # í† ë¡ ë¬¸ ì¬ë°°ì—´
    letter2text = {}
    for line in debate_blocks:
        m = re.match(r"^(.+?)\s+\[([ABCD])\]:\s*(.*)$", line, re.S)
        if m:
            letter2text[m.group(2)] = (m.group(1), m.group(3))
    debate_lines = []
    for L in perm:
        role, txt = letter2text.get(L, (f"AI?{L}", ""))
        debate_lines.append(f"{role} [{L}]: {txt}")

    judge_instruction = (
        f"ë„ˆëŠ” ì„œë¡œ ë…ë¦½ì ì¸ {size}ëª…ì˜ ì‹¬ì‚¬ìœ„ì›(J1..J{size})ì„ ë™ì‹œì— ì—°ê¸°í•œë‹¤.\n"
        "ê° ì‹¬ì‚¬ìœ„ì›ì€ ê°€ì¥ ì„¤ë“ë ¥ ìˆëŠ” ì„ íƒì§€ í•œ ê°œ(A/B/C/D)ë§Œ ê³ ë¥¸ë‹¤.\n"
        "ì¶œë ¥ì€ **ì˜¤ì§ í•˜ë‚˜ì˜ JSON ê°ì²´**ë¡œ, ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤(ì„¤ëª…/ì½”ë“œíœìŠ¤/ë¹ˆì¤„ ê¸ˆì§€):\n"
        '{"J1":"A","J2":"C","J3":"B","J4":"C","J5":"D"}'
    )
    judge_user = (
        "ë¬¸ì œì™€ ì„ íƒì§€(ë¬´ì‘ìœ„ ìˆœì„œ):\n"
        f"Q: {q['question']}\n" + "\n".join(choices_lines) +
        "\n\në‹¤ìŒì€ ê° AIì˜ ì£¼ì¥(ë¬´ì‘ìœ„ ìˆœì„œ)ì´ë‹¤. ê° ì‹¬ì‚¬ìœ„ì›ì˜ ì„ íƒë§Œ JSONìœ¼ë¡œ ì¶œë ¥í•˜ë¼.\n\n" +
        "\n\n".join(debate_lines)
    )
    return judge_instruction, judge_user

def _extract_pick(v) -> str:
    """ê°’ì—ì„œ A/B/C/D 1ê¸€ìë§Œ ë½‘ê¸°."""
    if isinstance(v, str):
        m = re.search(r"\b([ABCD])\b", v.upper())
        return m.group(1) if m else ""
    if isinstance(v, dict):
        for kk in ("pick", "answer", "choice", "final"):
            s = v.get(kk)
            if isinstance(s, str) and s.upper() in LETTERS:
                return s.upper()
    return ""

def _parse_bundle_vote_json(payload: str, size: int = 5) -> List[str]:
    """{"J1":"A",...} ê°™ì´ ì˜¨ JSONì„ [p1..pN] ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜. í‚¤ëŠ” ëŒ€ì†Œë¬¸ì/ê³µë°± í—ˆìš©."""
    d = safe_json_loads(payload) or {}
    picks = [""] * size
    if not isinstance(d, dict):
        return picks

    for k, v in d.items():
        kstr = str(k)
        m = re.match(r"^\s*(?:J|Judge)?\s*(\d+)\s*$", kstr, re.I)
        if not m:
            continue
        idx = int(m.group(1))
        if 1 <= idx <= size:
            picks[idx - 1] = _extract_pick(v)
    return picks

def run_bundle_judges(judge_model_name: str, q: dict, debate_blocks: List[str],
                      size: int, num_ctx: int, seed: int) -> Tuple[List[str], str]:
    """ì €ì§€ 1ì¸Nì—­: í•œ ë²ˆì˜ í˜¸ì¶œë¡œ Ní‘œ ë°˜í™˜."""
    perm = LETTERS[:]
    random.shuffle(perm)
    instr, user = make_judge_bundle_payload(q, debate_blocks, perm, size=size)
    raw = chat_once(
        judge_model_name,
        [{"role": "system", "content": instr}, {"role": "user", "content": user}],
        temperature=0.0, top_p=1.0, num_ctx=num_ctx, seed=seed
    )
    picks = _parse_bundle_vote_json(raw, size=size)
    return picks, raw

# ================== í‰ê°€(ì €ì§€) ==================
def evaluate_one(qid: str, q: dict, debater_models: List[str], judge_model: str,
                 temperature: float, top_p: float, max_sents: int,
                 num_debaters: int, retry_judge: bool = True, domain: Optional[str] = None,
                 multi_voice: bool = True, single_debater_model: Optional[str] = None,
                 # === ì •í™•ë„ í–¥ìƒ ì¸ìë“¤ ===
                 n_debate: int = 1, n_judge: int = 1, judge_models_multi: Optional[List[str]] = None,
                 use_score_mode: bool = False, num_ctx: int = 8192, seed_base: int = 42,
                 top_k: int = 40, repeat_penalty: float = 1.1,
                 # === NEW ë²ˆë“¤ ì €ì§€ ===
                 use_bundle_judge: bool = True, judge_bundle_size: int = 5):
    """ë‹¤ì¤‘ í† ë¡ Â·ë‹¤ì¤‘ ì €ì§€ ì•™ìƒë¸” (ë²ˆë“¤ ì €ì§€ ì§€ì›)."""
    judge_models_multi = judge_models_multi or [judge_model]

    normalize_item_in_place(q)
    validate_item_or_stop(qid, q)

    tally = {L: 0 for L in LETTERS}
    last_debaters, last_blocks = [], []
    last_raws = []

    for d_idx in range(n_debate):
        # --- í† ë¡  ìƒ˜í”Œ ìƒì„± ---
        if multi_voice and single_debater_model:
            debaters, debate_blocks = generate_debate_bundle_single(
                single_debater_model, q, max_sents, temperature, top_p,
                num_ctx=num_ctx, seed=seed_base + d_idx,
                top_k=top_k, repeat_penalty=repeat_penalty
            )
        else:
            debaters, debate_blocks = [], []
            for i, letter in enumerate(LETTERS):
                ai_role = f"AI{i+1}"
                claim = q["choices"][letter]
                system_prompt = make_debater_system(ai_role, letter, claim, max_sents)
                user_msg = make_debater_user(q, letter)
                model_for_role = debater_models[i % max(1, num_debaters)]
                try:
                    content = chat_once(
                        model_for_role,
                        [{"role": "system", "content": system_prompt},
                         {"role": "user", "content": user_msg}],
                        temperature=temperature, top_p=top_p,
                        num_ctx=num_ctx, seed=seed_base + d_idx,
                        top_k=top_k, repeat_penalty=repeat_penalty
                    )
                except Exception as e:
                    content = f"[ì˜¤ë¥˜] ëª¨ë¸ ì‘ë‹µ ì‹¤íŒ¨: {e}"
                debaters.append({"role": ai_role, "letter": letter, "content": content})
                debate_blocks.append(f"{ai_role} [{letter}]: {content}")

        # --- ì €ì§€ ---
        if use_bundle_judge:
            jm = judge_models_multi[0]  # ë²ˆë“¤ ëª¨ë“œì—ì„œëŠ” ëŒ€í‘œ 1ê°œ ëª¨ë¸ë§Œ ì‚¬ìš©(í•„ìš”ì‹œ ë¼ìš´ë“œ ë¡œë¹ˆ ê°€ëŠ¥)
            picks, raw = run_bundle_judges(
                jm, q, debate_blocks, size=judge_bundle_size,
                num_ctx=num_ctx, seed=seed_base + 10_000 * d_idx
            )
            last_raws.append(f"[bundle {jm} x{judge_bundle_size}] {raw}")
            for p in picks:
                if p in LETTERS:
                    tally[p] += 1
        else:
            for v in range(n_judge):
                jm = judge_models_multi[v % len(judge_models_multi)]
                pick, raw = run_one_judge_vote(
                    jm, q, debate_blocks,
                    mode_scores=use_score_mode,
                    num_ctx=num_ctx,
                    seed=seed_base + 10_000 * d_idx + v
                )
                last_raws.append(f"[{jm}] {raw}")
                if pick in LETTERS:
                    tally[pick] += 1

        last_debaters, last_blocks = debaters, debate_blocks

    final_choice = max(LETTERS, key=lambda L: (tally[L], L))
    correct = (final_choice == q["answer"])

    a_text = next((d["content"] for d in last_debaters if d["letter"] == "A"), "")
    b_text = next((d["content"] for d in last_debaters if d["letter"] == "B"), "")
    c_text = next((d["content"] for d in last_debaters if d["letter"] == "C"), "")
    d_text = next((d["content"] for d in last_debaters if d["letter"] == "D"), "")

    return {
        "qid": qid,
        "domain": domain or "",
        "topic": q.get("topic", ""),
        "question": q["question"],
        "gold": q["answer"],
        "judge": final_choice or "",
        "correct": bool(correct),
        "judge_raw": f"tally={tally}\n" + "\n".join(last_raws[-min(len(last_raws), 5):]),
        "A_text": a_text, "B_text": b_text, "C_text": c_text, "D_text": d_text,
        "perm": "",
    }

# ================== í† í”½(ë¬¸ì œ ìœ í˜•) í•„í„° ==================
def topic_of(q: dict) -> str:
    t = (q.get("topic") or "").strip()
    return t if t else "(ë¯¸ë¶„ë¥˜)"

def list_topics(mmlu_data: dict) -> List[str]:
    return sorted({topic_of(q) for q in mmlu_data.values()})

def filter_qids_by_topic(mmlu_data: dict, qids: List[str], picked_topics: List[str]) -> List[str]:
    picked = set(picked_topics)
    return [qid for qid in qids if topic_of(mmlu_data[qid]) in picked]

# ================== ì•± ==================
st.set_page_config(page_title="MMLU Debate Evaluation", layout="wide")
st.sidebar.title("ğŸ§  MMLU í† ë¡  í‰ê°€")

# ë°ì´í„° ë¡œë“œ
mmlu_data, domain_index, qid2domain = load_questions()
all_qids = list(mmlu_data.keys())
if not all_qids:
    st.error("ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤. JSON íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”."); st.stop()

# í† í”½(ë¬¸ì œ ìœ í˜•) í•„í„°
st.sidebar.markdown("### ğŸ—‚ ë¬¸ì œ ìœ í˜•(í† í”½) í•„í„°")
all_topics = list_topics(mmlu_data)
picked_topics = st.sidebar.multiselect("ìœ í˜• ì„ íƒ(ë³µìˆ˜ ê°€ëŠ¥)", all_topics, default=all_topics)

# Ollama ì¤€ë¹„ & ëª¨ë¸ ëª©ë¡
check_ollama()
try:
    model_list = [m["model"] for m in ollama.list()["models"]]
except Exception as e:
    st.error(f"Ollama ëª¨ë¸ ëª©ë¡ ì˜¤ë¥˜: {e}"); st.stop()
if not model_list:
    st.error("ì„¤ì¹˜ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. `ollama pull mistral` ë“±ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”."); st.stop()

# === (ì˜µì…˜) ì‚¬ì´ë“œë°”: ë²ˆí˜¸ í˜•ì‹ ì˜ê²¬ ìƒì„±ê¸° ===
with st.sidebar:
    st.markdown("---")
    st.markdown("### ğŸ§ª ë²ˆí˜¸ í˜•ì‹ ì˜ê²¬ ìƒì„±")
    N_num = st.number_input("ì¤„ ìˆ˜(N)", min_value=2, max_value=6, value=2, step=1, key="sb_lines")
    topic_num = st.text_input("ì£¼ì œ(ì˜ˆ: ë¬´ìŠ¨ ì˜·ì„ ì…ì„ê¹Œ?)", key="sb_topic_numbered")
    default_name = "gemma3:latest"
    default_idx = model_list.index(default_name) if default_name in model_list else 0
    gen_model = st.selectbox("ì‹¤í–‰ ëª¨ë¸", model_list, index=default_idx, key="sb_model_numbered")
    sb_temp = st.slider("temperature(opinion)", 0.0, 1.5, 0.6, 0.1, key="sb_temp_numbered")
    sb_topp = st.slider("top_p(opinion)", 0.1, 1.0, 0.95, 0.05, key="sb_topp_numbered")
    if st.button("â–¶ ë²ˆí˜¸ í˜•ì‹ ìƒì„±", key="sb_make_numbered"):
        if not (topic_num or "").strip():
            st.warning("ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            sys = (
                "ë„ˆëŠ” ì‚¬ìš©ì ì£¼ì œì— ëŒ€í•´ ì„œë¡œ ëŒ€ë¹„ë˜ëŠ” ì—¬ëŸ¬ ì…ì¥ì„ ë§Œë“ ë‹¤.\n"
                f"ì¶œë ¥ì€ **ì˜¤ì§ {N_num}ì¤„**, ê° ì¤„ì€ ìˆ«ìì™€ ì ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•œë‹¤. ë‹¤ë¥¸ ë§/ì½”ë“œíœìŠ¤/ë¹ˆ ì¤„ ê¸ˆì§€.\n"
                f"í˜•ì‹ ì˜ˆì‹œ: 1. â€¦\\n2. â€¦\\n...\\n{N_num}. â€¦\n"
                "í•œêµ­ì–´ë§Œ ì‚¬ìš©."
            )
            usr = f"ì£¼ì œ: {topic_num}"
            raw = chat_once(
                gen_model,
                [{"role": "system", "content": sys},
                 {"role": "user", "content": usr}],
                temperature=sb_temp, top_p=sb_topp
            )
            text = (raw or "").strip()
            pairs = re.findall(r"(?m)^\s*(\d+)\.\s*(.+?)\s*$", text)
            by_num = {}
            for num_str, content in pairs:
                try:
                    k = int(num_str)
                except ValueError:
                    continue
                if 1 <= k <= N_num and k not in by_num:
                    by_num[k] = content.strip()
            if len(by_num) < N_num:
                lines = [l.strip() for l in text.splitlines() if l.strip()]
                for l in lines:
                    if len(by_num) >= N_num:
                        break
                    if not re.match(r"^\d+\.\s*", l):
                        by_num[len(by_num) + 1] = l
            contents = [by_num.get(i, "") for i in range(1, int(N_num) + 1)]
            final = topic_num.strip() + "\n" + "\n".join(f"{i}. {c}" for i, c in enumerate(contents, 1))
            st.markdown("**ê²°ê³¼**")
            st.code(final)

# ê³µí†µ í•˜ì´í¼íŒŒë¼ë¯¸í„°
st.sidebar.markdown("### âš™ï¸ ê³µí†µ ì„¤ì •")
temperature = st.sidebar.slider("temperature", 0.0, 1.5, 0.2, 0.1)
top_p = st.sidebar.slider("top_p", 0.1, 1.0, 0.9, 0.05)
max_sents = st.sidebar.slider("ë°œì–¸ ë¬¸ì¥ ìˆ˜(ê¶Œì¥ ìµœëŒ€)", 3, 8, 6, 1)

# ëª¨ë“œ ì „í™˜: 1ì¸ ë‹¤ì—­(ë©€í‹°ë³´ì´ìŠ¤)
st.sidebar.markdown("---")
multi_voice = st.sidebar.checkbox("âš¡ 1ì¸ ë‹¤ì—­(í•œ ëª¨ë¸ë¡œ A/B/C/D ìƒì„±, 1ì½œ)", value=True)

# ëª¨ë¸ ì„ íƒ
st.sidebar.markdown("### ğŸ¤– í† ë¡ ì & ì €ì§€ ëª¨ë¸")
if multi_voice:
    single_debater_model = st.sidebar.selectbox("í† ë¡ ì(1ì¸ ë‹¤ì—­) ëª¨ë¸", model_list, key="single_deb_model")
    debater_models = [single_debater_model]
    num_debaters = 1
else:
    num_debaters = st.sidebar.slider("í† ë¡ ì ìˆ˜", 1, 4, 4)
    debater_models = [st.sidebar.selectbox(f"í† ë¡ ì ëª¨ë¸ {i+1}", model_list, key=f"deb_model_{i+1}") for i in range(num_debaters)]
    single_debater_model = None

judge_default = model_list.index("mistral") if "mistral" in model_list else 0
judge_model = st.sidebar.selectbox("Judge ê¸°ë³¸ ëª¨ë¸", model_list, index=judge_default)

# === ì •í™•ë„ í–¥ìƒ ì˜µì…˜ ===
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ§ª ì •í™•ë„ í–¥ìƒ ì˜µì…˜")
n_debate = st.sidebar.slider("Debate ìƒ˜í”Œ ìˆ˜(ìê¸°ì¼ê´€ì„±)", 1, 5, 3)
# ë²ˆë“¤ ì €ì§€: 1ì¸5ì—­ ê³ ì •
use_bundle_judge = st.sidebar.checkbox("1ì¸ Nì—­ ë²ˆë“¤ ì €ì§€ ì‚¬ìš©", value=True)
judge_bundle_size = st.sidebar.number_input("ë²ˆë“¤ ì €ì§€ ì¸ì›(N)", min_value=5, max_value=5, value=5, step=0, help="ìš”ì²­ì— ë”°ë¼ 5ë¡œ ê³ ì •")
# (ë¹„ë²ˆë“¤ìš©) ì €ì§€ íˆ¬í‘œìˆ˜/ëª¨ë“œ
n_judge = st.sidebar.slider("ì €ì§€ íˆ¬í‘œ ìˆ˜(ë¹„ë²ˆë“¤ ëª¨ë“œìš©)", 1, 9, 5, step=2)
scoring_mode = st.sidebar.selectbox("ë¹„ë²ˆë“¤ ì €ì§€ ë°©ì‹", ["íƒœê·¸ 1ì¤„(`<answer>X</answer>`)","JSON ì ìˆ˜({\"A\":0-100,...})"], index=0)

judge_models_multi = st.sidebar.multiselect(
    "ì €ì§€ ëª¨ë¸(ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥, ë²ˆë“¤ì€ ì²« ëª¨ë¸ë§Œ ì‚¬ìš©)",
    model_list,
    default=[judge_model] if judge_model in model_list else []
)
if not judge_models_multi:
    judge_models_multi = [judge_model]

# ëª¨ë¸ ì˜µì…˜ ë³´ê°•
num_ctx = st.sidebar.number_input("num_ctx(ì»¨í…ìŠ¤íŠ¸)", 2048, 32768, 8192, step=1024)
top_k = st.sidebar.number_input("top_k", 16, 200, 40, step=8)
repeat_penalty = st.sidebar.number_input("repeat_penalty", 1.0, 2.0, 1.1, step=0.05)
seed_base = st.sidebar.number_input("seed(ì¬í˜„ì„±)", 0, 10_000_000, 42, step=1)
st.sidebar.caption("ë²ˆë“¤ ì €ì§€: í•œ ë²ˆ í˜¸ì¶œë¡œ 5í‘œ ìƒì„± â†’ ì†ë„/ì•ˆì •ì„± í–¥ìƒ")

# ì‹¤í–‰ ëª¨ë“œ
mode = st.radio("ì‹¤í–‰ ëª¨ë“œ ì„ íƒ", ["ë‹¨ì¼ ë¬¸ì œ", "ì „ì²´ í‰ê°€"], horizontal=True)

# ---------------- ë‹¨ì¼ ë¬¸ì œ ----------------
if mode == "ë‹¨ì¼ ë¬¸ì œ":
    filtered_qids = filter_qids_by_topic(mmlu_data, all_qids, picked_topics)
    if not filtered_qids:
        st.warning("ì„ íƒëœ í† í”½ì— í•´ë‹¹í•˜ëŠ” ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ í† í”½ì„ ì¡°ì •í•˜ì„¸ìš”."); st.stop()

    topics_for_pick = sorted({topic_of(mmlu_data[qid]) for qid in filtered_qids})
    chosen_topic = st.selectbox("ë¬¸ì œ ìœ í˜•(í† í”½)", topics_for_pick)
    topic_qids = [qid for qid in filtered_qids if topic_of(mmlu_data[qid]) == chosen_topic]

    qid = st.selectbox("ë¬¸ì œ ì„ íƒ", topic_qids, key="single_qid")
    q = mmlu_data[qid]

    normalize_item_in_place(q)
    validate_item_or_stop(qid, q)

    st.caption(f"ìœ í˜•: {topic_of(q)}")
    st.markdown(f"### â“ {q['question']}")
    st.markdown("**ì„ íƒì§€**")
    for k in LETTERS:
        st.markdown(f"- **{k}**: {q['choices'][k]}")

    if st.button("ğŸš€ í† ë¡  ì‹œì‘ + ì €ì§€ ì±„ì "):
        with st.spinner("í† ë¡  ìƒì„± ì¤‘..."):
            if multi_voice and single_debater_model:
                debaters, debate_blocks = generate_debate_bundle_single(
                    single_debater_model, q, max_sents, temperature, top_p,
                    num_ctx=num_ctx, seed=seed_base, top_k=top_k, repeat_penalty=repeat_penalty
                )
            else:
                debaters, debate_blocks = [], []
                for i, letter in enumerate(LETTERS):
                    ai_role = f"AI{i+1}"
                    claim = q["choices"][letter]
                    system_prompt = make_debater_system(ai_role, letter, claim, max_sents)
                    user_msg = make_debater_user(q, letter)
                    model_for_role = debater_models[i % max(1, num_debaters)]
                    try:
                        content = chat_once(
                            model_for_role,
                            [{"role": "system", "content": system_prompt},
                             {"role": "user", "content": user_msg}],
                            temperature=temperature, top_p=top_p,
                            num_ctx=num_ctx, seed=seed_base, top_k=top_k, repeat_penalty=repeat_penalty
                        )
                    except Exception as e:
                        content = f"[ì˜¤ë¥˜] ëª¨ë¸ ì‘ë‹µ ì‹¤íŒ¨: {e}"
                    debaters.append({"role": ai_role, "letter": letter, "content": content})
                    debate_blocks.append(f"{ai_role} [{letter}]: {content}")

        st.subheader("ğŸ’¬ AI ë°œì–¸")
        for d in debaters:
            st.markdown(f"**{d['role']} ({d['letter']} ì£¼ì¥)**")
            st.info(d["content"])

        # ì €ì§€ (ì•™ìƒë¸”)
        st.subheader("âš–ï¸ Judge ëª¨ë¸ íŒë‹¨")
        res = evaluate_one(
            qid=qid, q=q,
            debater_models=debater_models,
            judge_model=judge_model,
            temperature=temperature, top_p=top_p,
            max_sents=max_sents, num_debaters=(num_debaters if not multi_voice else 1),
            retry_judge=True, domain=qid2domain.get(qid),
            multi_voice=multi_voice, single_debater_model=single_debater_model,
            # ì •í™•ë„ í–¥ìƒ ì¸ì
            n_debate=n_debate, n_judge=n_judge, judge_models_multi=judge_models_multi,
            use_score_mode=(scoring_mode.startswith("JSON")),
            num_ctx=num_ctx, seed_base=seed_base, top_k=top_k, repeat_penalty=repeat_penalty,
            # ë²ˆë“¤ ì €ì§€(1ì¸5ì—­)
            use_bundle_judge=use_bundle_judge, judge_bundle_size=judge_bundle_size
        )

        final_choice = res["judge"]
        judge_raw = res["judge_raw"]

        if not final_choice:
            st.error("Judge ì¶œë ¥ì—ì„œ A/B/C/Dë¥¼ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.markdown(f"**Judge ì„ íƒ:** {final_choice}")
            st.markdown(f"**ì •ë‹µ:** {q['answer']}")
            st.success("ì •ë‹µê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤! âœ…") if final_choice == q["answer"] else st.error("ì •ë‹µê³¼ ë¶ˆì¼ì¹˜! âŒ")
            with st.expander("ì €ì§€ ë¡œê·¸ ë³´ê¸°"):
                st.code(judge_raw)

# ---------------- ì „ì²´ í‰ê°€ ----------------
else:
    st.markdown("### ğŸ“š ì „ì²´ í‰ê°€ ì„¤ì •")

    filtered_qids = filter_qids_by_topic(mmlu_data, all_qids, picked_topics)
    if not filtered_qids:
        st.warning("ì„ íƒëœ í† í”½ì— í•´ë‹¹í•˜ëŠ” ë¬¸í•­ì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ í† í”½ì„ ì¡°ì •í•˜ì„¸ìš”."); st.stop()

    random_order = st.checkbox("ë¬¸ì œ ìˆœì„œ ì„ê¸°", value=False)
    seed = st.number_input("ëœë¤ ì‹œë“œ", value=42, step=1)
    max_count = st.slider("í‰ê°€í•  ë¬¸ì œ ê°œìˆ˜", 1, len(filtered_qids), len(filtered_qids))
    show_logs = st.checkbox("ë¬¸í•­ë³„ ìƒì„¸ ë¡œê·¸ í‘œì‹œ", value=False)

    selected_qids = filtered_qids.copy()
    if random_order:
        random.Random(seed).shuffle(selected_qids)
    selected_qids = selected_qids[:max_count]

    if st.button("ğŸ§ª ì „ì²´ í‰ê°€ ì‹œì‘"):
        results, start_time = [], time.time()
        progress = st.progress(0, text="ì‹œì‘ ì¤‘...")

        for idx, qid in enumerate(selected_qids, start=1):
            q = mmlu_data[qid]
            normalize_item_in_place(q)
            validate_item_or_stop(qid, q)

            progress.progress(idx / max_count, text=f"{idx}/{max_count} í‰ê°€ ì¤‘: {qid}")
            res = evaluate_one(
                qid=qid, q=q,
                debater_models=debater_models,
                judge_model=judge_model,
                temperature=temperature, top_p=top_p,
                max_sents=max_sents, num_debaters=(num_debaters if not multi_voice else 1),
                retry_judge=True, domain=qid2domain.get(qid),
                multi_voice=multi_voice, single_debater_model=single_debater_model,
                # ì •í™•ë„ í–¥ìƒ ì¸ì
                n_debate=n_debate, n_judge=n_judge, judge_models_multi=judge_models_multi,
                use_score_mode=(scoring_mode.startswith("JSON")),
                num_ctx=num_ctx, seed_base=seed_base, top_k=top_k, repeat_penalty=repeat_penalty,
                # ë²ˆë“¤ ì €ì§€(1ì¸5ì—­)
                use_bundle_judge=use_bundle_judge, judge_bundle_size=judge_bundle_size
            )
            results.append(res)

            if show_logs:
                with st.expander(f"[{idx}] {qid} | ë¶„ì•¼: {qid2domain.get(qid, q.get('topic',''))} | ì •ë‹µ: {res['gold']} | Judge: {res['judge']} | {'âœ…' if res['correct'] else 'âŒ'}"):
                    st.write(q["question"])
                    st.write({k: v for k, v in q["choices"].items()})
                    st.markdown("**Judge ì›ë¬¸/ë¡œê·¸(ì¼ë¶€)**"); st.code(res["judge_raw"])
                    st.markdown("**AI1 (A) ë°œì–¸**"); st.info(res["A_text"])
                    st.markdown("**AI2 (B) ë°œì–¸**"); st.info(res["B_text"])
                    st.markdown("**AI3 (C) ë°œì–¸**"); st.info(res["C_text"])
                    st.markdown("**AI4 (D) ë°œì–¸**"); st.info(res["D_text"])

        total_time = time.time() - start_time
        progress.progress(1.0, text="ì™„ë£Œ")

        # ìš”ì•½
        df = pd.DataFrame(results)
        st.markdown("## ğŸ“ˆ ê²°ê³¼ ìš”ì•½")
        if df.empty:
            st.warning("ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."); st.stop()
        acc = df["correct"].mean()
        c1, c2, c3 = st.columns(3)
        c1.metric("ì´ ë¬¸í•­", len(df))
        c2.metric("ì •í™•ë„(%)", f"{acc*100:.1f}")
        c3.metric("ì´ ì†Œìš”ì‹œê°„(ì´ˆ)", f"{total_time:.1f}")

        # ë¶„ì•¼ë³„/í† í”½ë³„ ì •í™•ë„
        st.markdown("### ğŸ§­ ë¶„ì•¼ë³„ ì •í™•ë„ (domain)")
        if "domain" in df.columns:
            dom_acc = df.groupby("domain")["correct"].mean().sort_values(ascending=False)
            st.dataframe(dom_acc.to_frame("accuracy").assign(accuracy=lambda x: (x["accuracy"]*100).round(1)))

        st.markdown("### ğŸ§­ ì£¼ì œë³„ ì •í™•ë„ (topic)")
        if "topic" in df.columns:
            topic_acc = df.groupby("topic")["correct"].mean().sort_values(ascending=False)
            st.dataframe(topic_acc.to_frame("accuracy").assign(accuracy=lambda x: (x["accuracy"]*100).round(1)))

        # í˜¼ë™ í–‰ë ¬
        st.markdown("### ğŸ” í˜¼ë™ í–‰ë ¬ (Judge vs ì •ë‹µ)")
        cm = pd.crosstab(df["gold"], df["judge"], dropna=False).reindex(index=LETTERS, columns=LETTERS, fill_value=0)
        st.dataframe(cm)

        # CSV ë‹¤ìš´ë¡œë“œ
        st.markdown("### â¬‡ï¸ ê²°ê³¼ ì €ì¥")
        csv = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="mmlu_batch_results.csv", mime="text/csv")
