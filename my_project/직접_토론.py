import streamlit as st
import re
import json
import uuid
import ollama
from utils import check_ollama

# ============== ìœ í‹¸ ==============
def clean_surrogates(text: str) -> str:
    return re.sub(r'[\ud800-\udfff]', '', text or "")

def chat_once(model: str, messages: list, temperature: float, top_p: float, keep_alive: str = "5m"):
    res = ollama.chat(
        model=model,
        messages=messages,
        stream=False,
        options={
            "temperature": float(temperature),
            "top_p": float(top_p),
            "keep_alive": keep_alive
        }
    )
    return clean_surrogates(res.get("message", {}).get("content", ""))

# ============== ì•± ==============
st.set_page_config(page_title="User vs AI Debate", page_icon="ğŸ¤–")
st.title("ğŸ‘¤ ì‚¬ìš©ì vs ğŸ¤– AI Debate")

# ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "judge_result" not in st.session_state:
    st.session_state.judge_result = ""

if "model" not in st.session_state:
    check_ollama()
    try:
        models = [m["model"] for m in ollama.list()["models"]]
    except Exception:
        models = []
    st.session_state.model = models[0] if models else ""

# â”€â”€ ì‚¬ì´ë“œë°” ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("âš™ï¸ Debate Settings")

    # í† ë¡  ì£¼ì œ ì…ë ¥
    topic = st.text_input("í† ë¡  ì£¼ì œ ì…ë ¥", key="debate_topic")

    # ì£¼ì œ ì¶”ì²œ (AI ìƒì„±)
    prefer = st.text_input("ì¶”ì²œ ë°›ì„ ì£¼ì œ ì…ë ¥", key="prefer")
    if st.button("ğŸ² ì£¼ì œ ì¶”ì²œ ë°›ê¸°"):
        sys = "ë‹¤ì–‘í•œ í† ë¡  ì£¼ì œë¥¼ 5ê°œ ì œì‹œí•´ë¼. ê°„ê²°í•˜ê³  í•œêµ­ì–´ë¡œ."
        usr = f"{prefer}ê³¼ ê´€ë ¨ëœ í¥ë¯¸ë¡œìš´ í† ë¡  ì£¼ì œë¥¼ ì¶”ì²œí•´ì¤˜."
        raw = chat_once("mistral", [{"role":"system","content":sys},{"role":"user","content":usr}], 0.7, 0.9)
        st.session_state.recommended_topics = raw.strip().split("\n")

    if "recommended_topics" in st.session_state:
        st.markdown("#### ì¶”ì²œ ì£¼ì œ")
        for t in st.session_state.recommended_topics:
            st.markdown(t)

    # AI ëª¨ë¸ ì„ íƒ
    model = st.selectbox("AI ëª¨ë¸ ì„ íƒ", ollama.list()["models"], format_func=lambda m: m["model"], key="model_select")

    # ë‚œì´ë„ ìŠ¬ë¼ì´ë” (1=ì‰¬ì›€, 3=ì–´ë ¤ì›€)
    difficulty_level = st.slider("ë‚œì´ë„", 1, 3, 2)
    difficulty_map = {
        1: "AIëŠ” ì•½ê°„ í—ˆì ì´ ìˆê³ , ë…¼ë¦¬ë¥¼ ì™„ë²½íˆ ì „ê°œí•˜ì§€ ì•ŠëŠ”ë‹¤.",
        2: "AIëŠ” ë…¼ë¦¬ì ìœ¼ë¡œ ê· í˜• ì¡íŒ ë°˜ë°•ì„ í•œë‹¤.",
        3: "AIëŠ” ë§¤ìš° ë‚ ì¹´ë¡­ê³  ê³µê²©ì ìœ¼ë¡œ ë°˜ë°•í•˜ë©°, ìƒëŒ€ë°©ì˜ ì•½ì ì„ ì§‘ìš”í•˜ê²Œ íŒŒê³ ë“ ë‹¤."
    }
    difficulty_prompt = difficulty_map[difficulty_level]

    # AI ì£¼ì¥(ì„¸íŒ…)
    debate_role = st.text_area("AI ì£¼ì¥ ì„¸íŒ…", value="ì˜ˆ) ì°¨ê°‘ê³  ë¬´ëšëší•˜ë‹¤.")

    # íŒŒë¼ë¯¸í„°
    temperature = st.slider("Temperature", 0.0, 1.5, 0.7, 0.1)
    top_p = st.slider("Top-p", 0.1, 1.0, 0.95, 0.05)

# â”€â”€ ë©”ì¸ ì±„íŒ… ì˜ì—­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ëŒ€í™” ê¸°ë¡ ì¶œë ¥
for msg in st.session_state.messages:
    avatar = "ğŸ‘¤" if msg["role"] == "user" else "ğŸ¤–"
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ë‹¹ì‹ ì˜ ì£¼ì¥ì´ë‚˜ ë°˜ë°•ì„ ì…ë ¥í•˜ì„¸ìš”")
if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(user_input)

    # AI ì‘ë‹µ ì¤€ë¹„
    sys_prompt = (
        f"ë‹¹ì‹ ì€ í† ë¡  ì°¸ì—¬ìì…ë‹ˆë‹¤. ì£¼ì œëŠ” '{topic}' ì…ë‹ˆë‹¤.\n"
        "ì ˆëŒ€ ì¤‘ë¦½ì ì´ì§€ ë§ê³ , ìì‹ ì˜ ì…ì¥ì„ ê°•í•˜ê²Œ ì˜¹í˜¸í•˜ì„¸ìš”. "
        "ìƒëŒ€ë°©ì˜ ì•½ì ì„ ë°˜ë“œì‹œ ì§€ì í•˜ê³  ë°˜ë°•í•´ì•¼ í•©ë‹ˆë‹¤.\n"
        f"{difficulty_prompt}\n\n"
        f"ì•„ë˜ëŠ” ë‹¹ì‹ ì˜ ê³ ì •ëœ ì£¼ì¥ ì„¸íŒ…ì…ë‹ˆë‹¤:\n{debate_role}"
    )
    messages = [{"role": "system", "content": sys_prompt}] + st.session_state.messages

    with st.chat_message("assistant", avatar="ğŸ¤–"):
        with st.spinner("AIê°€ ë°˜ë°•ì„ ì¤€ë¹„ ì¤‘..."):
            try:
                ai_reply = chat_once(st.session_state.model, messages, temperature, top_p)
            except Exception as e:
                ai_reply = f"(ì—ëŸ¬ ë°œìƒ: {e})"
            st.markdown(ai_reply)

    # AI ë©”ì‹œì§€ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": ai_reply})

# â”€â”€ Judge ëª¨ë¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.button("ğŸ§‘â€âš–ï¸ Judge í‰ê°€í•˜ê¸°"):
    judge_instruction = (
        f"ë‹¹ì‹ ì€ ê³µì •í•œ í† ë¡  ì‹¬íŒìì…ë‹ˆë‹¤. ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ ì½ê³  Userì™€ AI ì¤‘ ëˆ„ê°€ ë” ë…¼ë¦¬ì ì´ê³  ì„¤ë“ë ¥ ìˆì—ˆëŠ”ì§€ íŒì •í•˜ì„¸ìš”.\n"
        f"ìŠ¹ìë¥¼ ì •í•˜ê³ , ê°ìì˜ ìŠ¹ë¥ ì„ ë°±ë¶„ìœ¨ë¡œ ë‚˜ëˆ„ì–´ ì£¼ì„¸ìš”.\n"
        f"ì¶œë ¥ í˜•ì‹:\n\n"
        f"[ìŠ¹ì] : User ë˜ëŠ” AI\n[ìŠ¹ë¥ ] : User xx% - AI xx%\n[ì´ìœ ] : ..."
    )
    judge_prompt = [{"role": "system", "content": judge_instruction}] + st.session_state.messages
    try:
        judge_result = chat_once("mistral", judge_prompt, temperature=0.0, top_p=1.0)
    except Exception:
        judge_result = "íŒì • ì‹¤íŒ¨"
    st.session_state.judge_result = judge_result

if st.session_state.judge_result:
    st.markdown("### ğŸ§‘â€âš–ï¸ Judge ê²°ê³¼")
    st.info(st.session_state.judge_result)
