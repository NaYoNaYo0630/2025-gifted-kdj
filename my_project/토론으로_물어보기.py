# -*- coding: utf-8 -*-
# í† ë¡ ìœ¼ë¡œ ë¬¼ì–´ë³´ê¸° (ì„±ëŠ¥ë¹„êµ ë©”ì»¤ë‹ˆì¦˜ + ì •í™•ë„ í–¥ìƒ ì˜µì…˜ + ìš°ì„¸ í‘œì‹œ + max_turns ë£¨í”„)
#
# ìœ ì§€/ê°œì„  ìš”ì•½:
#  - ëª¨ë¸ë³„ "ì—­í•  ë²ˆë“¤(JSON)" 1ì½œ ìƒì„±(ì„±ëŠ¥ë¹„êµì‹ ì•ˆì „ íŒŒì‹±)
#  - ë§¤ í„´ ì¢…ë£Œ ì‹œ: ì €ì§€(JSON) â†’ ê° ì—­í•  ì¡°ì–¸ ìˆ¨ê¹€ì£¼ì… â†’ ë‹¤ìŒ í„´ì— ë°˜ì˜
#  - ë§¤ í„´ ì¢…ë£Œ ì‹œ: ì €ì§€ ì•™ìƒë¸” ì ìˆ˜(0~100) í‰ê· /í‘œì¤€í¸ì°¨ í‘œì‹œ, ìš°ì„¸ í‘œì‹œ
#  - ë§ˆì§€ë§‰ì—: ìµœì¢… ì €ì§€ ìš”ì•½(ë‚´ìš© ìš”ì•½, ê° ì„ ìˆ˜ ì¥/ë‹¨ì , ìµœì¢… ìš°ìœ„/ìš°ìŠ¹) í‘œì‹œ
#  - ì‚¬ìš©ì ìŠ¹ì ì„ íƒ & ì´ì–´ê°€ê¸° ë²„íŠ¼ ì œê³µ
#  - ê²¬ê³  JSON íŒŒì„œ(safe_json_loads v2), ì €ì§€ ì›ë¬¸ ë””ë²„ê·¸(expander)
#  - max_turns ë§Œí¼ ìë™ ì§„í–‰

import re
import json
import uuid
from typing import Dict, List, Optional

import streamlit as st
import ollama
from utils import check_ollama

# =============== ê³µí†µ ìƒìˆ˜ ===============
MAX_AI = 5

# =============== ìœ í‹¸ ===============
def clean_surrogates(text: str) -> str:
    return re.sub(r'[\ud800-\udfff]', '', text or "")

def safe_json_loads(payload: str) -> Optional[dict]:
    """
    ëª¨ë¸ì´ ì½”ë“œíœìŠ¤/ì„¤ëª…/í™‘ë”°ì˜´í‘œ/ê¼¬ë¦¬ì½¤ë§ˆë¥¼ ì„ì–´ë„ ìµœëŒ€í•œ ë³µêµ¬í•´ì„œ dictë¡œ ë°˜í™˜.
    ì‹¤íŒ¨ ì‹œ None.
    """
    if not payload:
        return None

    text = str(payload)

    # 0) ì½”ë“œíœìŠ¤/ë§ˆí¬ë‹¤ìš´ ì œê±°
    text = re.sub(r"^```[\w-]*\s*|\s*```$", "", text.strip(), flags=re.S)

    # 1) ê°€ì¥ ë°”ê¹¥ {} ë¸”ë¡ë§Œ ì •í™•íˆ ì¶”ì¶œ(ìŠ¤íƒ ë°©ì‹)
    def extract_outer_json_blob(s: str) -> Optional[str]:
        start = None
        depth = 0
        in_str = False
        esc = False
        for i, ch in enumerate(s):
            if in_str:
                if esc:
                    esc = False
                elif ch == '\\':
                    esc = True
                elif ch == '"':
                    in_str = False
                continue
            if ch == '"':
                in_str = True
                continue
            if ch == '{':
                if depth == 0:
                    start = i
                depth += 1
            elif ch == '}':
                if depth > 0:
                    depth -= 1
                    if depth == 0 and start is not None:
                        return s[start:i+1]
        return None

    blob = extract_outer_json_blob(text)
    if not blob:
        m = re.search(r"\{.*\}", text, re.S)
        blob = m.group(0) if m else None
    if not blob:
        return None

    # 2) 1ì°¨ ì‹œë„
    try:
        return json.loads(blob)
    except Exception:
        pass

    fixed = blob

    # 3) í™‘ë”°ì˜´í‘œ â†’ ìŒë”°ì˜´í‘œ(í‚¤/ë¬¸ìì—´ ê°’ë§Œ)
    def smart_quotes(s: str) -> str:
        s = re.sub(r"(?P<prefix>[\{\s,])'(?P<key>[^'\n\r\"]+?)'\s*:", r'\g<prefix>"\g<key>":', s)
        s = re.sub(r":\s*'(?P<val>[^'\n\r\"]+?)'(?P<tail>\s*[,}\]])", r': "\g<val>"\g<tail>', s)
        return s

    fixed = smart_quotes(fixed)

    # 4) íŠ¸ë ˆì¼ë§ ì½¤ë§ˆ ì œê±°
    fixed = re.sub(r",\s*([}\]])", r"\1", fixed)

    # 5) ë¹„í‘œì¤€ ì¹˜í™˜
    fixed = fixed.replace("NaN", "null").replace("Infinity", "1e9999").replace("-Infinity", "-1e9999")
    fixed = re.sub(r"\bTrue\b", "true", fixed)
    fixed = re.sub(r"\bFalse\b", "false", fixed)
    fixed = re.sub(r"\bNone\b", "null", fixed)

    try:
        return json.loads(fixed)
    except Exception:
        # 7) ìµœí›„ fallback: ì ìˆ˜ë§Œ íšŒìˆ˜
        scores = dict(re.findall(r'"(AI\d+)"\s*:\s*([+-]?\d+(?:\.\d+)?)', fixed))
        if scores:
            return {"scores": {k: float(v) for k, v in scores.items()}}
        return None


def chat_once(model: str, messages: list, temperature: float, top_p: float,
              keep_alive: str = "5m", **options) -> str:
    opts = {"temperature": float(temperature), "top_p": float(top_p), "keep_alive": keep_alive}
    opts.update(options or {})
    res = ollama.chat(model=model, messages=messages, stream=False, options=opts)
    return clean_surrogates(res.get("message", {}).get("content", ""))

# =============== ë²ˆë“¤ í† ë¡  ìƒì„±(ì„±ëŠ¥ë¹„êµì‹) ===============
def _extract_talk(value) -> str:
    if isinstance(value, str):
        return value.strip()
    if isinstance(value, dict):
        for k in ("talk", "speech", "content", "text", "message"):
            v = value.get(k)
            if isinstance(v, str):
                return v.strip()
        parts = [str(v).strip() for v in value.values() if isinstance(v, (str, int, float))]
        if parts:
            return " ".join(parts)
    if isinstance(value, list):
        parts = [str(x).strip() for x in value if isinstance(x, (str, int, float))]
        if parts:
            return " ".join(parts)
    return ""

def _normalize_debate_json(data: dict, roles: List[str]) -> Dict[str, str]:
    out = {r: "" for r in roles}
    if not isinstance(data, dict):
        return out
    normalized = {}
    for k, v in data.items():
        kstr = str(k).strip()
        m = re.match(r"^\s*AI\s*([1-9]\d*)\s*$", kstr, re.I)
        if m:
            normalized[f"AI{int(m.group(1))}"] = v
        else:
            normalized[kstr] = v
    for r in roles:
        v = normalized.get(r) or normalized.get(r.upper()) or normalized.get(r.lower())
        if v is not None:
            out[r] = _extract_talk(v)
    return out

def make_bundle_system(roles: List[str], lang: str, max_sents: int) -> str:
    lang_line = "í•œêµ­ì–´ë§Œ ì‚¬ìš©" if lang == "Korean" else "Use English only"
    keys_line = ", ".join(roles)
    json_schema_lines = ",\n".join([f'  "{r}": ""' for r in roles])
    return (
        f"ë„ˆëŠ” ë‹¤ìŒ ì°¸ê°€ìë“¤ì„ ë™ì‹œì— ì—°ê¸°í•œë‹¤: {keys_line}.\n"
        f"{lang_line}. ê° ì°¸ê°€ìëŠ” ìì‹ ì˜ ê³ ì • ì…ì¥(setting)ì„ ê°•í•˜ê²Œ ì˜¹í˜¸í•˜ê³ , ì¤‘ë¦½ í‘œí˜„ì„ í”¼í•˜ë©°, "
        f"ë‹¤ë¥¸ ì°¸ê°€ìì˜ ì£¼ì¥ ì•½ì ì„ ìµœì†Œ 1íšŒ ì§€ì í•œë‹¤. ê° ë°œì–¸ì€ ìµœëŒ€ {max_sents}ë¬¸ì¥.\n\n"
        "ì¶œë ¥ì€ **ì˜¤ì§ í•˜ë‚˜ì˜ JSON ê°ì²´**ë¡œ í•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…/ì½”ë“œíœìŠ¤/ì£¼ì„ ê¸ˆì§€. "
        "í‚¤ëŠ” ì•„ë˜ì™€ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•œë‹¤.\n"
        "{\n" + json_schema_lines + "\n}"
    )

def make_bundle_user(settings_map: Dict[str, str], topic_or_user_turn: str, lang: str) -> str:
    if lang == "Korean":
        header = "ì•„ë˜ëŠ” ì—­í• ë³„ ê³ ì • ì…ì¥(setting)ê³¼ í˜„ì¬ í† ë¡  ë§¥ë½ì´ë‹¤. ê° ì—­í• ì€ ìì‹ ì˜ ì„¤ì •ì„ ë°”íƒ•ìœ¼ë¡œ ë°œì–¸ì„ ìƒì„±í•˜ë¼."
    else:
        header = "Below are role settings and the current debate context. Generate each role's speech accordingly."
    settings_txt = "\n".join([f"- {k}: {v}" for k, v in settings_map.items()])
    return f"{header}\n\n[SETTINGS]\n{settings_txt}\n\n[CONTEXT]\n{topic_or_user_turn}"

def generate_bundle_for_group(
    model_name: str, roles: List[str], settings_map: Dict[str, str],
    lang: str, topic_or_user_turn: str,
    max_sents: int, temperature: float, top_p: float,
    num_ctx: int, seed: int, top_k: int, repeat_penalty: float
) -> Dict[str, str]:
    sys = make_bundle_system(roles, lang, max_sents)
    usr = make_bundle_user(settings_map, topic_or_user_turn, lang)
    raw = chat_once(
        model_name,
        [{"role": "system", "content": sys}, {"role": "user", "content": usr}],
        temperature=temperature, top_p=top_p,
        num_ctx=int(num_ctx), seed=int(seed), top_k=int(top_k), repeat_penalty=float(repeat_penalty)
    )
    data = safe_json_loads(raw) or {}
    talks = _normalize_debate_json(data, roles)
    for r in roles:
        if not talks.get(r, "").strip():
            talks[r] = "ë‚´ ì…ì¥ì„ ê°„ê²°í•˜ê²Œ ì¬ê°•ì¡°í•˜ê³ , ìƒëŒ€ ë…¼ì§€ì˜ ì•½ì ì„ í•œ ê°€ì§€ ì´ìƒ ì§€ì í•œë‹¤."
    return talks

# =============== Judge(ì ìˆ˜/ì¡°ì–¸/ìµœì¢…ìš”ì•½) ===============
JUDGE_MODEL = "mistral"  # ê¸°ë³¸ ì €ì§€ ëª¨ë¸

def build_judge_prompt(lang: str):
    if lang == "Korean":
        sys = (
            "ë‹¹ì‹ ì€ ê³µì •í•˜ê³  ì—„ê²©í•œ í† ë¡  ì‹¬íŒìì…ë‹ˆë‹¤. "
            "ëŒ€í™” ê¸°ë¡ ì „ì²´ë¥¼ ì½ê³ , ê° AIì˜ ìµœì‹  ì£¼ì¥ í’ˆì§ˆì„ í‰ê°€í•˜ê³  ë‹¤ìŒ ë¼ìš´ë“œë¥¼ ìœ„í•œ êµ¬ì²´ì  ê°œì„  ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤.\n"
            "ì˜¤ì§ í•˜ë‚˜ì˜ JSONìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ë§/ì½”ë“œíœìŠ¤/ì£¼ì„ ê¸ˆì§€. "
            "markdown ê¸ˆì§€, ``` ê¸ˆì§€, ë°˜ë“œì‹œ ìŠ¤í‚¤ë§ˆë¥¼ ì±„ì›Œ ì¶œë ¥.\n"
            "ìŠ¤í‚¤ë§ˆ ì˜ˆì‹œ:\n"
            "{\n"
            '  "winner": "AI1",\n'
            '  "scores": {"AI1": 0~10, "AI2": 0~10, ...},\n'
            '  "per_ai_advice": {\n'
            '     "AI1": {\n'
            '        "summary": "1~2ë¬¸ì¥ í•µì‹¬ ìš”ì•½",\n'
            '        "rebut_targets": ["AI2", "AI3"],\n'
            '        "fixes": ["ë…¼ë¦¬ì „ê°œ ê°œì„ ì  A", "ì¦ê±°/ì˜ˆì‹œ B"],\n'
            '        "evidence_requests": ["í†µê³„/ì‚¬ë¡€/ì •ì˜ ë“± ìš”ì²­ í¬ì¸íŠ¸"]\n'
            '     }\n'
            '  }\n'
            "}\n"
            "í‰ê°€ ê¸°ì¤€: ë…¼ë¦¬ì  ì¼ê´€ì„±, ë°˜ë°•ì˜ ì •í™•ë„, ê·¼ê±°ì˜ êµ¬ì²´ì„±, ì£¼ì¥ ê°•ë„(ë¹„ì¤‘ë¦½ì„±)."
        )
    else:
        sys = (
            "You are a rigorous debate judge. Read the entire conversation and output JSON with "
            "winner, per-AI numeric scores (0-10), and next-turn, actionable guidance for each AI. "
            "JSON only, no markdown, no codefence, fill the schema.\n"
            '{ "winner":"AI1", "scores":{"AI1":0-10,...}, "per_ai_advice":{"AI1":{"summary":"..","rebut_targets":[],"fixes":[],"evidence_requests":[]}} }'
        )
    return [{"role": "system", "content": sys}]

def get_judge_feedback(chat_messages: list, lang: str):
    prompt = build_judge_prompt(lang) + chat_messages
    raw = ""
    try:
        raw = chat_once(JUDGE_MODEL, prompt, temperature=0.0, top_p=1.0)
    except Exception:
        return None, "ì €ì§€ í˜¸ì¶œ ì‹¤íŒ¨"
    data = safe_json_loads(raw)
    if not data:
        st.session_state["_last_judge_raw"] = raw
        return None, "JSON íŒŒì‹± ì‹¤íŒ¨"
    scores = {k: float(v) for k, v in (data.get("scores") or {}).items()
              if str(v).replace('.','',1).isdigit()}
    data["scores"] = scores
    return data, None

def make_judge_scores_payload(chat_messages: List[dict], roles: List[str], lang: str) -> Dict[str, str]:
    if lang == "Korean":
        instr = (
            "ë„ˆëŠ” ê³µì •í•œ í† ë¡  ì‹¬íŒìë‹¤.\n"
            "í˜„ì¬ í„´ì˜ ê° ì°¸ê°€ì ë°œì–¸ì„ ë…¼ë¦¬ì„±/ê·¼ê±°ì˜ êµ¬ì²´ì„±/ë°˜ë¡  ì²˜ë¦¬ ê¸°ì¤€ìœ¼ë¡œ 0~100 ì ìˆ˜í™”í•˜ë¼.\n"
            "ì¶œë ¥ì€ **ì˜¤ì§ í•˜ë‚˜ì˜ JSON** í•œ ì¤„ë§Œ. ì˜ˆ: {\"AI1\":73,\"AI2\":64}\n"
        )
    else:
        instr = (
            "You are a fair debate judge.\n"
            "Score each participant's current-turn argument (0~100) for logic/evidence/rebuttals.\n"
            "Output ONLY one JSON line, e.g., {\"AI1\":73,\"AI2\":64}."
        )
    last_turn = [m for m in chat_messages if str(m.get("role","")).startswith("AI")]
    K = len(roles)
    last_turn = last_turn[-K:] if last_turn else []
    lines = [f"{m['role']}: {m['content']}" for m in last_turn]
    user = "\n".join(lines) if lines else "í˜„ì¬ í„´ ë°œì–¸ì´ ì—†ìŠµë‹ˆë‹¤."
    return {"system": instr, "user": user}

def parse_role_scores(payload: str, roles: List[str]) -> Dict[str, float]:
    d = safe_json_loads(payload) or {}
    out = {}
    for r in roles:
        try:
            out[r] = float(d.get(r, 0))
        except Exception:
            out[r] = 0.0
    return out

def make_judge_advice_payload(chat_messages: List[dict], roles: List[str], lang: str) -> Dict[str, str]:
    if lang == "Korean":
        instr = (
            "ë„ˆëŠ” í† ë¡  ì‹¬íŒ/ì½”ì¹˜ë‹¤.\n"
            "ê° ì°¸ê°€ì(AI1..N)ì— ëŒ€í•´ ë‹¤ìŒ JSONë§Œ ì¶œë ¥í•˜ë¼(ì½”ë“œíœìŠ¤/ì„¤ëª… ê¸ˆì§€):\n"
            '{"AI1":{"tip":"ë‹¤ìŒ í„´ì—ì„œ ê°œì„ í•  1~2ë¬¸ì¥ íŒ","rebut":"ë°˜ë°•í•´ì•¼ í•  ìƒëŒ€ í•µì‹¬ 1~2ê°œ"}, ...}\n'
        )
    else:
        instr = (
            "You are a debate judge/coach.\n"
            "Return ONLY one JSON: "
            '{"AI1":{"tip":"1-2 sentence actionable tip","rebut":"1-2 key opponent points to rebut"}, ...}'
        )
    last_turn = [m for m in chat_messages if str(m.get("role","")).startswith("AI")]
    K = len(roles)
    last_turn = last_turn[-K:] if last_turn else []
    lines = [f"{m['role']}: {m['content']}" for m in last_turn]
    user = "\n".join(lines) if lines else "í˜„ì¬ í„´ ë°œì–¸ì´ ì—†ìŠµë‹ˆë‹¤."
    return {"system": instr, "user": user}

def parse_advice(payload: str, roles: List[str]) -> Dict[str, Dict[str, str]]:
    d = safe_json_loads(payload) or {}
    out = {r: {"tip": "", "rebut": ""} for r in roles}
    if not isinstance(d, dict):
        return out
    for r in roles:
        v = d.get(r) or d.get(r.upper()) or d.get(r.lower())
        if isinstance(v, dict):
            tip = v.get("tip") or v.get("advice") or v.get("guide") or ""
            reb = v.get("rebut") or v.get("target") or v.get("opp") or ""
            out[r]["tip"] = str(tip).strip()
            out[r]["rebut"] = str(reb).strip()
        elif isinstance(v, str):
            parts = re.split(r"\s*;\s*|\n+", v.strip(), maxsplit=1)
            out[r]["tip"] = parts[0]
            out[r]["rebut"] = parts[1] if len(parts) > 1 else ""
    return out

def _strict_advice_call(model: str, payload: Dict[str, str], num_ctx: int, seed: int) -> str:
    return chat_once(
        model,
        [{"role": "system", "content": payload["system"]},
         {"role": "user", "content": payload["user"]}],
        temperature=0.0, top_p=1.0, num_ctx=int(num_ctx), seed=int(seed)
    )

def get_advice_with_retries(judge_models_multi: List[str], messages: List[dict], roles: List[str],
                            lang: str, num_ctx: int, seed: int) -> Dict[str, Dict[str, str]]:
    """
    - 1ì°¨: ë©€í‹°ì €ì§€ ì²« ëª¨ë¸ë¡œ ì—„ê²© í”„ë¡¬í”„íŠ¸ í˜¸ì¶œ
    - 2ì°¨: ì‹¤íŒ¨/ë¹ˆì¹¸ ìˆìœ¼ë©´ ë‹¤ë¥¸ ì €ì§€ ëª¨ë¸ë¡œ ì¬ì‹œë„
    - ê·¸ë˜ë„ ë¹ˆì¹¸ ìˆìœ¼ë©´ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ì±„ì›€
    """
    payload = make_judge_advice_payload(messages, roles, lang)

    tried = []
    # 1ì°¨ ì‹œë„
    m1 = judge_models_multi[0]
    tried.append(m1)
    raw1 = _strict_advice_call(m1, payload, num_ctx=num_ctx, seed=seed)
    adv = parse_advice(raw1, roles)

    def _has_empty(d):
        for r in roles:
            if not d.get(r, {}).get("tip") or not d.get(r, {}).get("rebut"):
                return True
        return False

    if not _has_empty(adv):
        return adv  # ì„±ê³µ

    # 2ì°¨ ì‹œë„(ë‹¤ë¥¸ ëª¨ë¸ë¡œ)
    if len(judge_models_multi) > 1:
        m2 = judge_models_multi[1]
    else:
        m2 = judge_models_multi[0]
    if m2 not in tried:
        raw2 = _strict_advice_call(m2, payload, num_ctx=num_ctx, seed=seed+777)
        adv2 = parse_advice(raw2, roles)
        # advì— ë¹ˆì¹¸ì¸ í•­ëª©ë§Œ ë³´ì™„
        for r in roles:
            if not adv.get(r, {}).get("tip") and adv2.get(r, {}).get("tip"):
                adv[r]["tip"] = adv2[r]["tip"]
            if not adv.get(r, {}).get("rebut") and adv2.get(r, {}).get("rebut"):
                adv[r]["rebut"] = adv2[r]["rebut"]

    # 3) íœ´ë¦¬ìŠ¤í‹± ë³´ì •
    return fill_missing_advice(adv, roles, messages)

def fill_missing_advice(adv: Dict[str, Dict[str, str]], roles: List[str], messages: List[dict]) -> Dict[str, Dict[str, str]]:
    """
    - ìµœê·¼ ì €ì§€ í”¼ë“œë°±(per_ai_advice)ì—ì„œ summary/fixes/targetsë¥¼ ê°€ì ¸ì™€ ì±„ì›€
    - ì—†ìœ¼ë©´ ìµœê·¼ í„´ì˜ ìƒëŒ€ ë°œì–¸ì„ ê¸°ì¤€ìœ¼ë¡œ ê¸°ë³¸ ë¬¸ì¥ ìƒì„±
    """
    last_judge = st.session_state.get("last_judge", {}) or {}
    per_ai = (last_judge.get("per_ai_advice") or {}) if isinstance(last_judge, dict) else {}

    # ìµœê·¼ í„´ì˜ AI ë°œì–¸ ë§µ
    last_ai_msgs = [m for m in messages if str(m.get("role","")).startswith("AI")]
    role_to_text = {}
    if last_ai_msgs:
        # ë§ˆì§€ë§‰ ë¼ìš´ë“œë§Œ ì¶”ì •
        k = len(roles)
        for m in last_ai_msgs[-k:]:
            role_to_text[m["role"]] = m.get("content","")

    all_roles = set(roles)
    for r in roles:
        tip = adv.get(r, {}).get("tip", "").strip()
        rebut = adv.get(r, {}).get("rebut", "").strip()

        # ì €ì§€ ì›ìë£Œì—ì„œ ëŒì–´ì˜¤ê¸°
        src = per_ai.get(r, {}) if isinstance(per_ai, dict) else {}
        if not tip:
            fixes = src.get("fixes") or src.get("tip")
            summary = src.get("summary", "")
            if isinstance(fixes, list) and fixes:
                tip = " / ".join([str(x) for x in fixes[:2]])
            elif isinstance(fixes, str) and fixes.strip():
                tip = fixes.strip()
            elif summary:
                tip = summary.strip()

        if not rebut:
            # ì €ì§€ê°€ ì§€ì •í•œ ë°˜ë°• ëŒ€ìƒ
            targets = src.get("rebut_targets") or src.get("rebut") or []
            if isinstance(targets, str):
                targets = [targets]
            targets = [t for t in targets if str(t).upper() in all_roles]
            if targets:
                rebut = f"{', '.join(targets)}ì˜ í•µì‹¬ ë…¼ì§€ë¥¼ êµ¬ì²´ì  ê·¼ê±°ë¡œ ë°˜ë°•í•˜ë¼."
            else:
                # ìƒëŒ€ ì¤‘ í•˜ë‚˜ ì„ íƒ(ê°„ë‹¨ íœ´ë¦¬ìŠ¤í‹±)
                others = [x for x in roles if x != r]
                # ìƒëŒ€ ìµœì‹  ë°œì–¸ ì¤‘ ê¸¸ì´ê°€ ê¸´ ìª½ì„ ìš°ì„  íƒ€ê¹ƒ
                if others:
                    best = max(others, key=lambda o: len(role_to_text.get(o,"")))
                    rebut = f"{best}ê°€ ì œì‹œí•œ ìµœê·¼ ê·¼ê±°ì˜ ì „ì œ/ìˆ˜ì¹˜ì˜ íƒ€ë‹¹ì„±ì„ ê²€ì¦í•´ ë°˜ë°•í•˜ë¼."

        # ìµœì¢… ë¹„ì–´ìˆìŒ ë°©ì§€: ê¸°ë³¸ ë¬¸ì¥
        if not tip:
            tip = "í•µì‹¬ ì£¼ì¥ í•œ ë¬¸ë‹¨ì„ ë” ì„ ëª…í•˜ê²Œ ì¬êµ¬ì„±í•˜ê³ , êµ¬ì²´ì  ìˆ˜ì¹˜Â·ì‚¬ë¡€ 1ê°œë¥¼ ì¶”ê°€í•˜ë¼."
        if not rebut:
            # ë‚¨ì€ ìƒëŒ€ ì¤‘ í•˜ë‚˜
            others = [x for x in roles if x != r]
            target = others[0] if others else "ìƒëŒ€"
            rebut = f"{target}ì˜ ê°€ì¥ ê°•í•œ ì£¼ì¥ í•˜ë‚˜ë¥¼ ê³¨ë¼ ë…¼ë¦¬ì  ì „ì œì™€ ê·¼ê±°ì˜ ì‹ ë¢°ë„ë¥¼ ì§šì–´ ë°˜ë°•í•˜ë¼."

        adv.setdefault(r, {})
        adv[r]["tip"] = tip
        adv[r]["rebut"] = rebut

    return adv


def ensemble_judge_scores(
    judge_models_multi: List[str], n_judge: int,
    messages: List[dict], roles: List[str],
    num_ctx: int, seed_base: int
) -> Dict[str, float]:
    totals = {r: 0.0 for r in roles}
    squares = {r: 0.0 for r in roles}
    logs = []
    for v in range(n_judge):
        jm = judge_models_multi[v % len(judge_models_multi)]
        payload = make_judge_scores_payload(messages, roles, st.session_state.languages)
        raw = chat_once(
            jm,
            [{"role": "system", "content": payload["system"]},
             {"role": "user", "content": payload["user"]}],
            temperature=0.0, top_p=1.0, num_ctx=int(num_ctx), seed=int(seed_base + v)
        )
        scores = parse_role_scores(raw, roles)
        logs.append(f"[{jm}] {raw}")
        for r in roles:
            s = float(scores.get(r, 0.0))
            totals[r] += s
            squares[r] += s * s
    means = {r: totals[r] / max(1, n_judge) for r in roles}
    if n_judge > 1:
        stds = {r: (squares[r] / n_judge - means[r] ** 2) ** 0.5 for r in roles}
    else:
        stds = {r: 0.0 for r in roles}
    st.session_state["_judge_logs"] = logs[-min(5, len(logs)):]
    st.session_state["_judge_stds"] = stds
    return means

# ìµœì¢… ìš”ì•½ ì €ì§€
def build_final_summary_prompt(lang: str):
    if lang == "Korean":
        sys = (
            "ë„ˆëŠ” í† ë¡  ìµœì¢… ì‹¬íŒìë‹¤. ì „ì²´ ëŒ€í™”ë¥¼ ì½ê³  ë‹¤ìŒ JSONë§Œ ì¶œë ¥í•˜ë¼(ì½”ë“œíœìŠ¤/ì„¤ëª… ê¸ˆì§€):\n"
            "{\n"
            '  "summary": "ì „ì²´ í† ë¡  í•µì‹¬ì„ 3~5ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½",\n'
            '  "per_ai": {\n'
            '     "AI1": {"strengths": ["ê°•ì 1","ê°•ì 2"], "weaknesses": ["ì•½ì 1","ì•½ì 2"]},\n'
            '     "AI2": {"strengths": [...], "weaknesses": [...]}\n'
            '  },\n'
            '  "final_winner": "AI1",\n'
            '  "reason": "ìµœì¢… ìš°ìœ„/íŒë‹¨ ê·¼ê±°ë¥¼ 2~4ë¬¸ì¥"\n'
            "}\n"
            "JSONë§Œ ì¶œë ¥. markdown/í…ìŠ¤íŠ¸ ê¸ˆì§€."
        )
    else:
        sys = (
            "You are the final debate judge. Read the whole conversation and output ONLY JSON:\n"
            '{ "summary":"3-5 sentence recap", "per_ai":{"AI1":{"strengths":[],"weaknesses":[]},...}, "final_winner":"AI1", "reason":"2-4 sentences" }'
        )
    return [{"role": "system", "content": sys}]

def get_final_summary(chat_messages: list, roles: List[str], lang: str):
    prompt = build_final_summary_prompt(lang) + chat_messages
    raw = chat_once(JUDGE_MODEL, prompt, temperature=0.0, top_p=1.0)
    data = safe_json_loads(raw)
    if not data:
        st.session_state["_last_final_judge_raw"] = raw
        return None, "ìµœì¢… ìš”ì•½ JSON íŒŒì‹± ì‹¤íŒ¨"
    # per_ai í‚¤ ë³´ì •
    per_ai = {}
    got = data.get("per_ai") or {}
    for r in roles:
        v = got.get(r) or got.get(r.upper()) or got.get(r.lower()) or {}
        per_ai[r] = {
            "strengths": list(v.get("strengths") or []),
            "weaknesses": list(v.get("weaknesses") or [])
        }
    data["per_ai"] = per_ai
    return data, None

def _parse_last_judge_scores(messages: List[dict], roles: List[str]) -> Optional[Dict[str, float]]:
    """
    chat_messagesì— ìš°ë¦¬ê°€ ì €ì¥í•´ë‘” system ë©”ì‹œì§€: {"role":"system","content":"[JUDGE_SCORES]{...}"}
    ë¥¼ ë’¤ì—ì„œë¶€í„° ì°¾ì•„ í‰ê· ì ìˆ˜ dictë¥¼ ë³µêµ¬.
    """
    for m in reversed(messages):
        if m.get("role") == "system":
            c = str(m.get("content", ""))
            if c.startswith("[JUDGE_SCORES]"):
                blob = c[len("[JUDGE_SCORES]"):]
                try:
                    d = safe_json_loads(blob) or json.loads(blob)
                    # rolesë§Œ í•„í„°
                    return {r: float(d.get(r, 0.0)) for r in roles}
                except Exception:
                    return None
    return None

def get_final_summary_robust(chat_messages: list, roles: List[str], lang: str,
                             judge_models_multi: List[str]):

    # 1) ë” ì—„ê²©í•œ í”„ë¡¬í”„íŠ¸(ë¹ˆ ê°’ ê¸ˆì§€, ë¯¸ê¸°ì¬ ì‹œ ê·œì¹™)
    if lang == "Korean":
        sys = (
            "ë„ˆëŠ” í† ë¡  ìµœì¢… ì‹¬íŒìë‹¤. ë°˜ë“œì‹œ ë‹¤ìŒ **ì™„ì „í•œ JSON**ë§Œ ì¶œë ¥í•˜ë¼.\n"
            "{\n"
            '  "summary": "ë¹ˆ ë¬¸ìì—´ ê¸ˆì§€. 3~5ë¬¸ì¥.",\n'
            '  "per_ai": {\n'
            '     "AI1": {"strengths": ["ìµœì†Œ1ê°œ"], "weaknesses": ["ìµœì†Œ1ê°œ"]},\n'
            '     "AI2": {"strengths": ["ìµœì†Œ1ê°œ"], "weaknesses": ["ìµœì†Œ1ê°œ"]}\n'
            '  },\n'
            '  "final_winner": "AI1 ë˜ëŠ” AI2 ë“± ì •í™•í•œ í‚¤",\n'
            '  "reason": "ë¹ˆ ë¬¸ìì—´ ê¸ˆì§€. 2~4ë¬¸ì¥."\n'
            "}\n"
            "í‚¤ ëˆ„ë½/ë¹ˆ ë¬¸ìì—´/ë¹ˆ ë°°ì—´ ê¸ˆì§€. ì–´ë–¤ ê²½ìš°ì—ë„ ìœ„ ìŠ¤í‚¤ë§ˆë¥¼ ì¶©ì¡±ì‹œì¼œ ì¶œë ¥í•  ê²ƒ. "
            "ì• ë§¤í•˜ë©´ ê°€ì¥ ì¼ê´€ëœ ë…¼ë¦¬ë¥¼ ë³´ì¸ ì°¸ê°€ìë¥¼ ìš°ìŠ¹ìë¡œ ì„ íƒí•˜ë¼."
        )
    else:
        sys = (
            "You are the final debate judge. Output ONLY a **complete JSON**:\n"
            '{ "summary":"3-5 sentences, not empty",'
            '  "per_ai":{"AI1":{"strengths":[">=1"],"weaknesses":[">=1"]},"AI2":{"strengths":[">=1"],"weaknesses":[">=1"]}},'
            '  "final_winner":"AI1|AI2|...", "reason":"2-4 sentences, not empty" }\n'
            "No missing keys, no empty strings/arrays. If uncertain, pick the participant with the most consistent logic."
        )

    prompt = [{"role": "system", "content": sys}] + chat_messages

    # 2) 1ì°¨ ì‹œë„: ê¸°ë³¸ JUDGE_MODEL
    raw = ""
    try:
        raw = chat_once(JUDGE_MODEL, prompt, temperature=0.0, top_p=1.0)
        data = safe_json_loads(raw)
    except Exception:
        data = None

    # 3) 2ì°¨ ì‹œë„: ë‹¤ë¥¸ judge ëª¨ë¸ë¡œ ì¬ì‹œë„
    if not data and judge_models_multi:
        alt = judge_models_multi[0]
        try:
            raw = chat_once(alt, prompt, temperature=0.0, top_p=1.0)
            data = safe_json_loads(raw)
        except Exception:
            data = None

    # 4) ë³´ì •: ìµœì†Œ í•„ë“œ ê°•ì œ
    result = {"summary": "", "per_ai": {}, "final_winner": "", "reason": ""}
    if isinstance(data, dict):
        result["summary"] = str(data.get("summary", "") or "").strip()
        result["final_winner"] = str(data.get("final_winner", "") or "").strip()
        result["reason"] = str(data.get("reason", "") or "").strip()
        got = data.get("per_ai") or {}
        for r in roles:
            v = got.get(r) or got.get(r.upper()) or got.get(r.lower()) or {}
            result["per_ai"][r] = {
                "strengths": list(v.get("strengths") or []),
                "weaknesses": list(v.get("weaknesses") or []),
            }

    # 5) ë¹ˆ ê°’ ë³´ì • ë¡œì§
    # (a) ìš°ìŠ¹ì ë¹„ì—ˆìœ¼ë©´: ë§ˆì§€ë§‰ Judge ì•™ìƒë¸” ì ìˆ˜ ë˜ëŠ” ì§ì „ judge_jsonì˜ winnerë¡œ ë³´ì •
    if not result["final_winner"]:
        by_scores = _parse_last_judge_scores(chat_messages, roles) or {}
        if by_scores:
            result["final_winner"] = max(by_scores, key=by_scores.get)
        else:
            last_j = st.session_state.get("last_judge", {}) or {}
            w = str((last_j.get("winner") or "")).strip()
            if w in roles:
                result["final_winner"] = w

    # (b) summary/ reason ë¹„ì—ˆìœ¼ë©´ ê°„ì´ ìš”ì•½ ìƒì„±
    if not result["summary"]:
        turns = sum(1 for m in chat_messages if str(m.get("role","")).startswith("AI"))
        result["summary"] = f"ì°¸ê°€ìë“¤ì€ ì´ {max(1, turns//len(roles))} ë¼ìš´ë“œ ë™ì•ˆ í•µì‹¬ ë…¼ì ì„ ì£¼ê³ ë°›ì•˜ë‹¤. ê°ìëŠ” ìì‹ ì˜ ì…ì¥ì„ ê°•í™”í•˜ê³  ìƒí˜¸ ë°˜ë°•ì„ ì œì‹œí–ˆë‹¤."
    if not result["reason"]:
        winner = result["final_winner"] or roles[0]
        result["reason"] = f"{winner}ê°€ ë…¼ë¦¬ì  ì¼ê´€ì„±ê³¼ êµ¬ì²´ì  ê·¼ê±° ì œì‹œì—ì„œ ìƒëŒ€ë¥¼ ì•ì„  ê²ƒìœ¼ë¡œ íŒë‹¨í–ˆë‹¤."

    # (c) per_aiì˜ strengths/weaknesses ì±„ìš°ê¸°
    per_ai_judge = (st.session_state.get("last_judge", {}) or {}).get("per_ai_advice", {}) or {}
    for r in roles:
        sw = result["per_ai"].setdefault(r, {"strengths": [], "weaknesses": []})
        if not sw["strengths"]:
            # íŒíŠ¸: fixes/summaryì—ì„œ ê°•ì  ìœ ì¶”
            src = per_ai_judge.get(r, {})
            summary = (src.get("summary") or "").strip()
            if summary:
                sw["strengths"].append(summary)
            sw["strengths"] = sw["strengths"] or ["í•µì‹¬ ì£¼ì¥ì„ ì¼ê´€ë˜ê²Œ ê°•ì¡°í•¨"]
        if not sw["weaknesses"]:
            src = per_ai_judge.get(r, {})
            reqs = src.get("evidence_requests") or []
            if isinstance(reqs, list) and reqs:
                sw["weaknesses"].append(f"ê·¼ê±° ë³´ê°• í•„ìš”: {reqs[0]}")
            sw["weaknesses"] = sw["weaknesses"] or ["ì •ëŸ‰ì  ê·¼ê±° ë˜ëŠ” ë°˜ë¡€ ì œì‹œê°€ ë¶€ì¡±í•¨"]

    return result, None


def _continue_ai_callback(chat_id: str, ai_choice: str):
    if chat_id not in st.session_state.chats:
        st.warning("ì±„íŒ…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    chat = st.session_state.chats[chat_id]
    try:
        ai_idx = int(ai_choice.replace("AI", "")) - 1
    except Exception:
        st.warning("ì˜¬ë°”ë¥¸ AIë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        return
    ai_role = f"AI{ai_idx+1}"

    setting = st.session_state.get(f"AI{ai_idx+1}_setting", "") or ""
    opponents = ", ".join([r for r in ai_roles if r != ai_role])

    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ì…ë ¥ ë˜ëŠ” í† ë¡  ì£¼ì œ ì¶”ì¶œ
    last_user_msg = ""
    for m in reversed(chat["messages"]):
        if m["role"] == "user":
            last_user_msg = m["content"]
            break

    if st.session_state.languages == "Korean":
        sys_prompt = (
            f"ë‹¹ì‹ ì€ {ai_role}ì´ë‹¤. {opponents}ì˜ ë…¼ì ì„ ì—¼ë‘ì— ë‘ë˜, ìì‹ ì˜ ë…¼ì§€ë¥¼ ë” ê¹Šê³  êµ¬ì²´ì ìœ¼ë¡œ ì „ê°œí•˜ë¼. {setting} (í”„ë¡¬í”„íŠ¸ ì–¸ê¸‰ ê¸ˆì§€.)"
        )
        usr_prompt = (
                f"ì´ì „ ëŒ€í™” ì£¼ì œ [{last_user_msg}]ì™€ ì§€ê¸ˆê¹Œì§€ì˜ í† ë¡  ë§¥ë½ì„ ê¸°ë°˜ìœ¼ë¡œ "
                f"{ai_role}ì˜ ì£¼ì¥ì„ ì´ì–´ê°€ë¼. "
                "ìƒˆë¡œìš´ ê·¼ê±° 1ê°œ ì´ìƒ í¬í•¨í•˜ê³ , ì €ì§€ì˜ ì¡°ì–¸ì„ ë°˜ì˜í•˜ë©°, ì§€ì •ëœ ë°˜ë°• ëŒ€ìƒì„ ìš°ì„  ë°˜ë°•í•˜ë¼."
            )
    else:
        sys_prompt = (
            f"You are {ai_role}. Consider {opponents}' points but extend your case with depth and specifics. {setting} (Do not mention the prompt.)"
        )
        usr_prompt = "Continue your key argument in â‰¤4 sentences. Include at least one new piece of evidence."

    last_judge = st.session_state.get("last_judge", {}) or {}
    per_ai = last_judge.get("per_ai_advice", {}) or {}
    adv = per_ai.get(ai_role, {}) or {}

    bullets = []
    rts = adv.get("rebut_targets") or adv.get("rebut") or []
    if isinstance(rts, str) and rts:
        rts = [rts]
    if rts:
        bullets.append("ìš°ì„  ë°˜ë°• ëŒ€ìƒ: " + ", ".join(map(str, rts)))
    fixes = adv.get("fixes") or adv.get("tip") or []
    if isinstance(fixes, str) and fixes:
        fixes = [fixes]
    if fixes:
        bullets.append("ê°œì„  ì§€ì‹œ: " + "; ".join(map(str, fixes)))
    reqs = adv.get("evidence_requests") or []
    if reqs:
        bullets.append("ê·¼ê±° ë³´ê°•: " + "; ".join(map(str, reqs)))
    if bullets:
        judge_hint = "[ì €ì§€ ì¡°ì–¸]\n- " + "\n- ".join(bullets)
        sys_prompt = judge_hint + "\n" + sys_prompt

    try:
        response = chat_once(
            st.session_state.get(f"AI{ai_idx+1}_model", models[0]),
            [{"role": "system", "content": sys_prompt}, {"role": "user", "content": usr_prompt}],
            temperature=temperature, top_p=top_p, num_ctx=int(num_ctx), seed=int(seed_base + 30_000)
        ) or "ê³„ì† ì£¼ì¥ì„ ì „ê°œí•©ë‹ˆë‹¤."
    except Exception as e:
        response = f"ê³„ì† ì£¼ì¥ì„ ì „ê°œí•©ë‹ˆë‹¤. (ìƒì„± ì‹¤íŒ¨: {e})"

    chat.setdefault("messages", [])
    chat["messages"].append({"role": ai_role, "content": response})

    st.session_state.show_user_judge = False
    st.session_state.user_judge_choice = ""
    st.session_state.last_manual_continue = {"ai": ai_role, "text": response}


def _manual_judge_advice_callback(chat_id: str):
    if chat_id not in st.session_state.chats:
        st.warning("ì±„íŒ…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    chat_msgs = st.session_state.chats[chat_id].get("messages", [])
    payload = make_judge_advice_payload(chat_msgs, ai_roles, st.session_state.languages)
    try:
        raw_adv = chat_once(
            judge_models_multi[0],
            [{"role": "system", "content": payload["system"]}, {"role": "user", "content": payload["user"]}],
            temperature=0.0, top_p=1.0, num_ctx=int(num_ctx), seed=int(seed_base + 40_000)
        )
        adv = parse_advice(raw_adv, ai_roles)
    except Exception as e:
        adv = {r: {"tip": f"ì €ì§€ í˜¸ì¶œ ì‹¤íŒ¨: {e}", "rebut": ""} for r in ai_roles}
        raw_adv = "(error)"

    st.session_state.judge_result = json.dumps(adv, ensure_ascii=False, indent=2)
    st.session_state.last_manual_judge_raw = raw_adv
    st.session_state.last_judge = {"winner": None, "scores": {}, "per_ai_advice": adv}


# =============== Streamlit ì•± ===============
st.set_page_config(page_title="AI Debate Room (ê°œì„ +ì •í™•ë„ì˜µì…˜+max_turns)", layout="wide")
st.sidebar.title("Settings")

# ì–¸ì–´
if "languages" not in st.session_state:
    st.session_state.languages = "Korean"
st.session_state.languages = st.sidebar.selectbox("Choose languages", ["Korean", "English"], index=0)

# AI ìˆ˜
if "NumberOfAi" not in st.session_state:
    st.session_state.NumberOfAi = 2
num_ai = st.sidebar.slider("AI ì¸ì›", 2, MAX_AI, st.session_state.NumberOfAi, 1)
st.session_state.NumberOfAi = num_ai
ai_roles = [f"AI{i+1}" for i in range(num_ai)]

# ëª¨ë¸ ëª©ë¡
check_ollama()
try:
    models = [m["model"] for m in ollama.list()["models"]]
except Exception:
    models = []
if not models:
    st.sidebar.error("ì„¤ì¹˜ëœ Ollama ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ì˜ˆ: `ollama pull mistral`")
    st.stop()

# ê° AIë³„ ëª¨ë¸ ì„ íƒ(ëª¨ë¸ë³„ ê·¸ë£¹ â†’ ê·¸ë£¹ 1ì½œ ë²ˆë“¤ ìƒì„±)
for i in range(num_ai):
    key = f"AI{i+1}_model"
    default_idx = 1 if st.session_state.get(key) not in models else models.index(st.session_state[key])
    st.sidebar.selectbox(f"AI{i+1} ëª¨ë¸", models, index=default_idx, key=key)

# ê° AI ì£¼ì¥ ì„±í–¥
for i in range(num_ai):
    key = f"AI{i+1}_setting"
    st.session_state[key] = st.sidebar.text_area(
        f"AI{i+1} ì£¼ì¥ ê²½í–¥ì„±",
        value=st.session_state.get(key, ""),
        help="ì˜ˆ) 'ì‚¬ê³¼ë¥¼ ë” ì„ í˜¸í•´', 'ì–´ë¦°ì´ ë§íˆ¬ë¡œ'... ë“±ë“±"
    )

# ë²ˆí˜¸ í˜•ì‹ ìë™ìƒì„±(ì›ê¸°ëŠ¥ ìœ ì§€)
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ§ª ë²ˆí˜¸ í˜•ì‹ ì˜ê²¬ ìƒì„±")
st.session_state.setdefault("numbered_topic", "")
st.session_state.setdefault("numbered_contents", None)

topic = st.sidebar.text_input("ì£¼ì œ(ì˜ˆ: ë¬´ìŠ¨ ì˜·ì„ ì…ì„ê¹Œ?)", key="sb_topic_numbered")
default_name = "gemma3:latest"
default_idx = models.index(default_name) if default_name in models else 1
gen_model = st.sidebar.selectbox("ì‹¤í–‰ ëª¨ë¸", models, index=default_idx, key="sb_model_numbered")
sb_temp = st.sidebar.slider("temperature(opinion)", 0.0, 1.5, 0.6, 0.1, key="sb_temp_numbered")
sb_topp = st.sidebar.slider("top_p(opinion)", 0.1, 1.0, 0.95, 0.05, key="sb_topp_numbered")

def _make_numbered(gen_model: str, topic: str, N: int) -> List[str]:
    sys = (
        "ë„ˆëŠ” ì‚¬ìš©ì ì£¼ì œì— ëŒ€í•´ ì„œë¡œ ëŒ€ë¹„ë˜ëŠ” ì—¬ëŸ¬ ì…ì¥ì„ ë§Œë“ ë‹¤.\n"
        f"ì¶œë ¥ì€ **ì˜¤ì§ {N}ì¤„**, ê° ì¤„ì€ ìˆ«ìì™€ ì ìœ¼ë¡œ ì‹œì‘. ì½”ë“œíœìŠ¤/ë¹ˆì¤„ ê¸ˆì§€.\n"
        f"ì˜ˆ: 1. â€¦\\n2. â€¦\\n...\\n{N}. â€¦\n"
        "ê° ì¤„ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ, í•œêµ­ì–´ë§Œ."
    )
    usr = f"ì£¼ì œ: {topic}"
    raw = chat_once(gen_model, [{"role": "system", "content": sys}, {"role": "user", "content": usr}],
                    temperature=sb_temp, top_p=sb_topp)
    text = (raw or "").strip()
    pairs = re.findall(r"(?m)^\s*(\d+)\.\s*(.+?)\s*$", text)
    by_num = {}
    for num_str, content in pairs:
        try:
            k = int(num_str)
        except ValueError:
            continue
        if 1 <= k <= N and k not in by_num:
            by_num[k] = content.strip()
    if len(by_num) < N:
        lines = [l.strip() for l in text.splitlines() if l.strip()]
        for l in lines:
            if len(by_num) >= N:
                break
            if not re.match(r"^\d+\.\s*", l):
                by_num[len(by_num) + 1] = l
    return [by_num.get(i, "") for i in range(1, N + 1)]

if st.sidebar.button("â–¶ ë²ˆí˜¸ í˜•ì‹ ìƒì„±", key="sb_make_numbered"):
    if not (topic or "").strip():
        st.sidebar.warning("ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        st.session_state["numbered_topic"] = (topic or "").strip()
        st.session_state["numbered_contents"] = _make_numbered(gen_model, topic, num_ai)
        st.sidebar.success(f"ì˜ê²¬ {num_ai}ê°œ ì €ì¥ ì™„ë£Œ")

if st.session_state.get("numbered_contents"):
    st.sidebar.markdown("**ê²°ê³¼**")
    if st.session_state.get("numbered_topic"):
        st.sidebar.markdown(f"- ì£¼ì œ: {st.session_state['numbered_topic']}")
    for i, c in enumerate(st.session_state["numbered_contents"], 1):
        st.sidebar.markdown(f"**{i}.**")
        st.sidebar.code(c or "", language="text")


# ê³µí†µ ìƒì„± í•˜ì´í¼íŒŒë¼ë¯¸í„°
st.sidebar.markdown("### âš™ï¸ ìƒì„± íŒŒë¼ë¯¸í„° (ì¡°ì •í•´ë„ ìœ ì˜ë¯¸í•œ ë³€í™” ì—†ìŒ)")
temperature = st.sidebar.slider("temperature", 0.0, 1.5, 0.4, 0.1)
top_p = st.sidebar.slider("top_p", 0.1, 1.0, 0.9, 0.05)
max_sents = st.sidebar.slider("ë°œì–¸ ë¬¸ì¥ ìˆ˜(ê¶Œì¥ ìµœëŒ€)", 3, 8, 6, 1)
max_turns = st.sidebar.slider("í† ë¡  ìµœëŒ€ í„´ìˆ˜", 1, 8, 3, 1)

# ì •í™•ë„ í–¥ìƒ ì˜µì…˜(ì €ì§€ ì•™ìƒë¸”)
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ§ª ì •í™•ë„ í–¥ìƒ ì˜µì…˜ (Judge ì•™ìƒë¸”)")
num_ctx = st.sidebar.number_input("num_ctx", 2048, 32768, 8192, step=1024)
top_k = st.sidebar.number_input("top_k", 8, 200, 40, step=8)
repeat_penalty = st.sidebar.number_input("repeat_penalty", 1.0, 2.0, 1.1, step=0.05)
seed_base = st.sidebar.number_input("seed", 0, 10_000_000, 42, step=1)

n_judge = st.sidebar.slider("ì €ì§€ í‘œ ìˆ˜(n_judge)", 1, 9, 5, step=2, help='ì´ ê°’ì€ í† ë¡  ì‹œê°„ì— í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. 1~3 ì¶”ì²œ')
judge_models_multi = st.sidebar.multiselect(
    "ì €ì§€ ëª¨ë¸(ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)",
    models,
    default=[m for m in ["mistral", "gemma3:latest"] if m in models] or [models[1]]
)
if not judge_models_multi:
    judge_models_multi = [models[0]]
st.sidebar.caption("ì—¬ëŸ¬ ì €ì§€ ëª¨ë¸ Ã— ì—¬ëŸ¬ í‘œ â†’ í‰ê· /í‘œì¤€í¸ì°¨ë¡œ ì•ˆì •í™”")

st.sidebar.markdown("### ğŸ§‘â€âš–ï¸ ì €ì§€ ì„¤ì •", help= 'ë‘ ê°œ ë‹¤ ì²´í¬í•´ ë†“ìœ¼ì‹œëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.')
use_judge_guidance = st.sidebar.checkbox("í„´ ì¢…ë£Œë§ˆë‹¤ ì €ì§€ í”¼ë“œë°± ë°˜ì˜", value=True)
show_judge_panel = st.sidebar.checkbox("ì €ì§€ ê²°ê³¼ íŒ¨ë„ ë³´ì´ê¸°", value=True)


# =============== ì±„íŒ… ì„¸ì…˜ ===============
if "chats" not in st.session_state:
    st.session_state.chats = {}
if "current_chat_id" not in st.session_state:
    st.session_state.current_chat_id = None

@st.dialog("ìƒˆ ì±„íŒ… ë§Œë“¤ê¸°")
def new_chat_dialog():
    chatings_name = st.text_input("ì±„íŒ… ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”", key="dlg_new_chat_name")
    if st.button("í™•ì¸", key="dlg_new_chat_ok"):
        name = (chatings_name or "").strip() or "Untitled Chat"
        chat_id = str(uuid.uuid4())
        st.session_state.current_chat_id = chat_id
        st.session_state.chats[chat_id] = {"name": name, "messages": []}
        st.rerun()

if st.sidebar.button("â• New Chat", key="sidebar_new_chat"):
    new_chat_dialog()

# ì±„íŒ… ëª©ë¡
for cid, chat_info in list(st.session_state.chats.items()):
    label = (chat_info.get("name") or "").strip() or "Untitled Chat"
    if st.sidebar.button(label, key=f"chat_btn_{cid}"):
        st.session_state.current_chat_id = cid
        st.rerun()

# ì•„ë°”íƒ€
emoji_numbers = ["1ï¸âƒ£", "2ï¸âƒ£", "3ï¸âƒ£", "4ï¸âƒ£", "5ï¸âƒ£"]
avatar_map = {f"AI{i+1}": emoji_numbers[i] for i in range(num_ai)}
avatar_map["user"] = "ğŸ‘¤"
st.session_state.avatar_map = avatar_map

# íŒë‹¨/ì¡°ì–¸ ìƒíƒœ
st.session_state.setdefault("show_user_judge", False)
st.session_state.setdefault("show_model_judge", False)
st.session_state.setdefault("user_judge_choice", "")
st.session_state.setdefault("judge_result", "")
st.session_state.setdefault("last_role_scores", {})
st.session_state.setdefault("_judge_logs", [])
st.session_state.setdefault("_judge_stds", {})

# =============== ë³¸ë¬¸ ===============
chat_id = st.session_state.current_chat_id
if chat_id:
    chat = st.session_state.chats[chat_id]
    st.title(chat["name"])

    # ê¸°ë¡ ë Œë”(ìˆ¨ê¹€/ë‚´ë¶€ ì§€ì‹œ ì œê±°)
    for msg in chat["messages"]:
        if msg["role"] == "system" or msg.get("_hidden"):
            continue
        if str(msg["role"]).endswith("_instruction"):
            continue
        with st.chat_message(msg["role"], avatar=avatar_map.get(msg["role"], "ğŸ’¬")):
            st.markdown(msg["content"])

    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.chat_input(topic)
    if user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥/í‘œì‹œ
        chat["messages"].append({"role": "user", "content": user_input})
        with st.chat_message("user", avatar=avatar_map["user"]):
            st.markdown(user_input)

        # ğŸ” max_turns ë£¨í”„ ì‹œì‘
        for turn in range(1, max_turns + 1):
            st.markdown(f"### ğŸ”„ Turn {turn}/{max_turns}")
            # ===== 1) ëª¨ë¸ë³„ ê·¸ë£¹ â†’ ë²ˆë“¤ 1ì½œ ìƒì„± =====
            model_groups: Dict[str, List[int]] = {}
            for i in range(num_ai):
                mname = st.session_state.get(f"AI{i+1}_model", models[0])
                model_groups.setdefault(mname, []).append(i)

            for mname, idxs in model_groups.items():
                roles = [f"AI{j+1}" for j in idxs]
                settings_map = {f"AI{j+1}": st.session_state.get(f"AI{j+1}_setting", "") for j in idxs}
                talks = generate_bundle_for_group(
                    model_name=mname, roles=roles, settings_map=settings_map,
                    lang=st.session_state.languages, topic_or_user_turn=user_input if turn == 1 else "ì´ì „ í„´ ë°œì–¸ê³¼ ì €ì§€ ì¡°ì–¸ì„ ë°˜ì˜í•´ ê³„ì† ì „ê°œ",
                    max_sents=max_sents, temperature=temperature, top_p=top_p,
                    num_ctx=num_ctx, seed=seed_base + 1000*turn, top_k=top_k, repeat_penalty=repeat_penalty
                )
                for r in roles:
                    text = talks.get(r, "")
                    # ì¤‘ë¦½ ê²½ê³ (ìˆ¨ê¹€ í”¼ë“œë°±)
                    if any(k in text.lower() for k in ["both", "depends", "personal preference", "ì¤‘ë¦½", "ê· í˜•", "equally valid"]):
                        warn = "âš ï¸ ë‹¹ì‹ ì˜ ë°œì–¸ì´ ë„ˆë¬´ ì¤‘ë¦½ì ì…ë‹ˆë‹¤. ìì‹ ì˜ ì…ì¥ì„ ê°•í•˜ê²Œ ë‹¤ì‹œ ì£¼ì¥í•˜ì„¸ìš”."
                        chat["messages"].append({"role": "user", "content": warn, "_hidden": True})
                    with st.chat_message(r, avatar=avatar_map[r]):
                        st.markdown(text)
                    chat["messages"].append({"role": r, "content": text})

            # ========== 2) í„´ ì¢…ë£Œ: ì €ì§€ í‰ê°€ & ë‹¤ìŒ í„´ ê°œì„  ì§€ì‹œ ì£¼ì… ==========
            if use_judge_guidance:
                judge_json, jerr = get_judge_feedback(chat["messages"], st.session_state.languages)
                st.session_state["last_judge"] = judge_json or {}
                st.session_state["last_judge_err"] = jerr

                if judge_json:
                    if show_judge_panel:
                        with st.expander(f"ğŸ§‘â€âš–ï¸ ì €ì§€ í”¼ë“œë°± (Turn {turn})", expanded=True):
                            winner = judge_json.get("winner", "N/A")
                            scores = judge_json.get("scores", {})
                            st.markdown(f"**ìš°ìŠ¹(ì„ì‹œ íŒë‹¨)**: {winner}")
                            if scores:
                                cols = st.columns(max(2, len(scores)))
                                for i, (k, v) in enumerate(sorted(scores.items())):
                                    with cols[i % len(cols)]:
                                        st.metric(k, f"{v:.1f}/10")
                            st.code(json.dumps(judge_json, ensure_ascii=False, indent=2), language="json")

                    # ìˆ¨ê¹€ ì§€ì‹œë¬¸ ì£¼ì…(ë‹¤ìŒ í„´ ë°˜ì˜)
                    per_ai = judge_json.get("per_ai_advice", {}) or {}
                    for i in range(num_ai):
                        ai_role = f"AI{i+1}"
                        adv = per_ai.get(ai_role, {})
                        if not adv:
                            continue
                        guide_lines = []
                        if adv.get("summary"):
                            guide_lines.append(f"[ì €ì§€ ìš”ì•½] {adv['summary']}")
                        rts = adv.get("rebut_targets") or []
                        if rts:
                            guide_lines.append(f"[ë°˜ë°• ëŒ€ìƒ] {', '.join(rts)}")
                        fixes = adv.get("fixes") or []
                        if fixes:
                            guide_lines.append("[ê°œì„  ì§€ì‹œ]\n- " + "\n- ".join(map(str, fixes)))
                        reqs = adv.get("evidence_requests") or []
                        if reqs:
                            guide_lines.append("[ê·¼ê±° ë³´ê°•]\n- " + "\n- ".join(map(str, reqs)))
                        setting = st.session_state.get(f"{ai_role}_setting", "")
                        setting_line = f"[ê³ ì • ì„¸íŒ… ì¬í™•ì¸] {setting}" if setting else ""
                        instruction_text = "\n".join([setting_line] + guide_lines).strip()
                        if instruction_text:
                            chat["messages"].append({"role": f"{ai_role}_instruction", "content": instruction_text})

                    chat["messages"].append({
                        "role": "user",
                        "content": ("ì €ì§€ì˜ ì¡°ì–¸ì„ ë°˜ì˜í•˜ì—¬ ë‹¤ìŒ í„´ì—ì„œ ì£¼ì¥ì„ ë” ê°•í•˜ê²Œ ì „ê°œí•˜ê³ , ì§€ì •ëœ ë°˜ë°• ëŒ€ìƒì„ ìš°ì„  ê³µëµí•˜ì„¸ìš”. ì¤‘ë¦½ì  ê²°ë¡  ê¸ˆì§€.")
                    })
                else:
                    pass
                    #if show_judge_panel and jerr:
                     #   with st.expander("ì €ì§€ ì›ë¬¸(íŒŒì‹± ì‹¤íŒ¨ ë””ë²„ê·¸)", expanded=False):
                      #      st.code(st.session_state.get("_last_judge_raw", "(ì›ë¬¸ ì—†ìŒ)"))
                       # st.warning(f"ì €ì§€ í”¼ë“œë°± ì˜¤ë¥˜: {jerr}")

            # ========== 3) í„´ ì¢…ë£Œ: ë‹¤ì¤‘ ì €ì§€ ì•™ìƒë¸” ìŠ¤ì½”ì–´ ==========
            means = ensemble_judge_scores(
                judge_models_multi=judge_models_multi,
                n_judge=int(n_judge),
                messages=chat["messages"],
                roles=ai_roles,
                num_ctx=int(num_ctx),
                seed_base=int(seed_base + 10_000 + 1000*turn)
            )
            stds = st.session_state["_judge_stds"]
            leader = max(ai_roles, key=lambda r: means.get(r, 0.0))
            with st.expander(f"âš–ï¸ Judge ì•™ìƒë¸” ì ìˆ˜ (Turn {turn})"):
                st.write({r: round(means.get(r, 0.0), 1) for r in ai_roles})
                if stds: 
                    st.caption("í‘œì¤€í¸ì°¨(ë‚®ì„ìˆ˜ë¡ í•©ì˜ ë†’ìŒ): " + ", ".join([f"{r}:{stds[r]:.1f}" for r in ai_roles]))
                st.info(f"ì´ë²ˆ í„´ ìš°ì„¸: **{leader}** (í‰ê·  {means.get(leader, 0):.1f})")
                with st.expander("ì €ì§€ ë¡œê·¸(ì¼ë¶€)"):
                    for line in st.session_state["_judge_logs"]:
                        st.code(line)

            chat["messages"].append({"role": "system", "content": f"[JUDGE_SCORES]{json.dumps(means, ensure_ascii=False)}", "_hidden": True})

            # ========== 4) Judge ëª¨ë¸ 'ë‹¤ìŒ í„´ ê°€ì´ë“œ' ìƒì„± & ìˆ¨ê¹€ ì£¼ì… ==========
            adv = get_advice_with_retries(
                judge_models_multi=judge_models_multi,
                messages=chat["messages"],
                roles=ai_roles,
                lang=st.session_state.languages,
                num_ctx=int(num_ctx),
                seed=int(seed_base + 20_000 + 1000*turn)
            )


            with st.expander(f"ğŸ§­ Judge ëª¨ë¸ ì¡°ì–¸(ë‹¤ìŒ í„´ ê°€ì´ë“œ Â· Turn {turn})"):
                for r in ai_roles:
                    tip = adv[r]["tip"]; reb = adv[r]["rebut"]
                    st.markdown(f"- **{r}** â†’ TIP: {tip or '(ë¹„ì–´ìˆìŒ)'} / REBUT: {reb or '(ë¹„ì–´ìˆìŒ)'}")

            chat["messages"].append({
                "role": "user",
                "content": f"[JUDGE_FEEDBACK]{json.dumps({'leader':leader,'advice':adv}, ensure_ascii=False)}",
                "_hidden": True
            })

        # ğŸ”š ëª¨ë“  í„´ ì¢…ë£Œ í›„: ìµœì¢… ìš”ì•½/ìš°ìŠ¹
        st.divider()
        st.markdown("## ğŸ ìµœì¢… ê²°ê³¼")
        final_json, ferr = get_final_summary_robust(
            chat["messages"], ai_roles, st.session_state.languages, judge_models_multi
        )
        if final_json:
            st.markdown("### ğŸ“œ ë‚´ìš© ìš”ì•½")
            st.write(final_json.get("summary", ""))
            st.markdown("### ğŸ§© ê° AI ì¥Â·ë‹¨ì ")
            for r in ai_roles:
                item = final_json["per_ai"].get(r, {"strengths": [], "weaknesses": []})
                st.markdown(f"**{r}**")
                st.write("- ê°•ì : " + (", ".join(item.get("strengths") or []) or "ì—†ìŒ"))
                st.write("- ì•½ì : " + (", ".join(item.get("weaknesses") or []) or "ì—†ìŒ"))
            st.markdown("### ğŸ† ìµœì¢… ìš°ìŠ¹ì")
            st.success(f'ìš°ìŠ¹: **{final_json.get("final_winner","N/A")}**')
            st.caption(final_json.get("reason", ""))
        else:
            with st.expander("ìµœì¢… ì €ì§€ ì›ë¬¸(íŒŒì‹± ì‹¤íŒ¨ ë””ë²„ê·¸)", expanded=False):
                st.code(st.session_state.get("_last_final_judge_raw", "(ì›ë¬¸ ì—†ìŒ)"))
            st.warning(f"ìµœì¢… ìš”ì•½ ì˜¤ë¥˜: {ferr or 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}")

    # ---- ğŸ‘¤ ì‚¬ìš©ì ìŠ¹ì ì„ íƒ / ì´ì–´ê°€ê¸° ----
    if st.button("ğŸ‘¤ ì‚¬ìš©ì ìŠ¹ì ì„ íƒ"):
        st.session_state.show_user_judge = True

    if st.session_state.get("show_user_judge", False):
        choice = st.selectbox("ìŠ¹ìë¥¼ ì„ íƒí•˜ì„¸ìš”", ai_roles, key="user_choice_select")
        st.session_state.user_judge_choice = choice
        st.success(f"ğŸ‘¤ ì‚¬ìš©ì íŒë‹¨: {choice} ìŠ¹ë¦¬!")

        st.button(
            "ì„ íƒëœ AIê°€ ì£¼ì¥ ì´ì–´ê°€ê¸°",
            on_click=_continue_ai_callback,
            args=(st.session_state.current_chat_id, choice)
        )

        st.button(
            "ğŸ§ JudgeModel ì¡°ì–¸(ìˆ˜ë™)",
            on_click=_manual_judge_advice_callback,
            args=(st.session_state.current_chat_id,)
        )

        if st.session_state.get("judge_result"):
            st.markdown("### ğŸ§­ JudgeModel íŒë‹¨/ì¡°ì–¸ (ìˆ˜ë™ ì €ì¥)")
            st.code(st.session_state.judge_result)
            if st.session_state.get("last_manual_judge_raw"):
                with st.expander("JudgeModel ì›ë¬¸(íŒŒì‹± ì‹¤íŒ¨ ë””ë²„ê·¸)", expanded=False):
                    st.code(st.session_state.last_manual_judge_raw)


else:
    st.info("ì˜¤ëŠ˜ì˜ í† ë¡  ì£¼ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?\nì™¼ìª½ì—ì„œ ì±„íŒ…ì„ ì„ íƒí•˜ê±°ë‚˜ ìƒˆ ì±„íŒ…ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.")
